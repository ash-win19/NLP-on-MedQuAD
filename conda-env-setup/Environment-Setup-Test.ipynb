{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd984907",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/medquad_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- System and Library Status ---\n",
      "Python OK: pandas 2.3.3, numpy 2.2.6, sklearn 1.7.2\n",
      "Torch Version: 2.8.0\n",
      "MPS (M4 GPU) available: True\n",
      "Using Device: mps\n",
      "\n",
      "--- Task 1/3: Generation (T5) Check ---\n",
      "T5 Model Load & Generation OK -> Welches ist der primäre Behandlung für Gla\n",
      "\n",
      "--- Task 2: Paraphrase/Embedding Check ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SBERT Model Load & Encode OK: Generated 2 vectors on mps:0\n",
      "\n",
      "--- Task 3: Retrieval Index Check ---\n",
      "BM25 Load & Scoring OK.\n",
      "FAISS Load & Indexing OK: 10 vectors indexed.\n",
      "\n",
      "--- Evaluation Metrics Check ---\n",
      "All Evaluation Metrics (ROUGE, BERTScore, sacreBLEU) Load OK.\n",
      "\n",
      "ALL PROJECT COMPONENTS READY ✅\n"
     ]
    }
   ],
   "source": [
    "import os, re, glob\n",
    "import torch, numpy as np, pandas as pd, sklearn\n",
    "import transformers, datasets, evaluate, spacy, sacrebleu\n",
    "from transformers import T5TokenizerFast, T5ForConditionalGeneration\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from rank_bm25 import BM25Okapi\n",
    "import faiss\n",
    "from rouge_score import rouge_scorer\n",
    "import xml.etree.ElementTree as ET\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "print(\"--- System and Library Status ---\")\n",
    "print(f\"Python OK: pandas {pd.__version__}, numpy {np.__version__}, sklearn {sklearn.__version__}\")\n",
    "\n",
    "# 1. PyTorch & GPU (M4 Mac) Check\n",
    "print(f\"Torch Version: {torch.__version__}\")\n",
    "mps_available = torch.backends.mps.is_available()\n",
    "print(f\"MPS (M4 GPU) available: {mps_available}\")\n",
    "# Define device to ensure all models are tested for the right hardware\n",
    "DEVICE = torch.device(\"mps\" if mps_available else \"cpu\")\n",
    "print(f\"Using Device: {DEVICE}\")\n",
    "\n",
    "# 2. Base Model and Tokenizer Check (Abstractive QA Task)\n",
    "print(\"\\n--- Task 1/3: Generation (T5) Check ---\")\n",
    "try:\n",
    "    tok = T5TokenizerFast.from_pretrained(\"t5-small\")\n",
    "    mdl = T5ForConditionalGeneration.from_pretrained(\"t5-small\").to(DEVICE) # Move model to GPU/MPS\n",
    "    \n",
    "    # Test generation execution flow\n",
    "    test_question = \"What is the primary treatment for glaucoma?\"\n",
    "    x = tok(test_question, return_tensors=\"pt\", truncation=True).input_ids.to(DEVICE)\n",
    "    y = mdl.generate(x, max_new_tokens=10)\n",
    "    print(\"T5 Model Load & Generation OK ->\", tok.decode(y[0], skip_special_tokens=True))\n",
    "except Exception as e:\n",
    "    print(f\"T5 Model Test FAILED: {e}\")\n",
    "\n",
    "# 3. Embedding Model Check (Paraphrase/Dense RAG)\n",
    "print(\"\\n--- Task 2: Paraphrase/Embedding Check ---\")\n",
    "try:\n",
    "    st_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\", device=str(DEVICE))\n",
    "    sample_texts = [\"leukemia symptoms\", \"blood cancer indicators\"]\n",
    "    # Encoding should successfully run on the determined DEVICE\n",
    "    vecs = st_model.encode(sample_texts, convert_to_tensor=True)\n",
    "    print(f\"SBERT Model Load & Encode OK: Generated {len(vecs)} vectors on {vecs.device}\")\n",
    "except Exception as e:\n",
    "    print(f\"SBERT Model Test FAILED: {e}\")\n",
    "\n",
    "# 4. Retrieval Indexing Check (RAG Task)\n",
    "print(\"\\n--- Task 3: Retrieval Index Check ---\")\n",
    "try:\n",
    "    # A. BM25 (Lexical) Check\n",
    "    test_corpus = [[\"adult\", \"acute\", \"leukemia\"], [\"pediatric\", \"flu\", \"treatment\"], [\"heart\", \"disease\", \"diagnosis\"]]\n",
    "    bm = BM25Okapi(test_corpus)\n",
    "    scores = bm.get_scores([\"leukemia\", \"acute\"])\n",
    "    print(\"BM25 Load & Scoring OK.\")\n",
    "\n",
    "    # B. FAISS (Dense) Check\n",
    "    # Use embedding dimension (384 for MiniLM-L6-v2) for index creation\n",
    "    D_size = 384\n",
    "    index = faiss.IndexFlatIP(D_size)\n",
    "    # Use synthetic random vectors for testing FAISS (np must be loaded)\n",
    "    synthetic_vecs = np.random.randn(10, D_size).astype('float32')\n",
    "    index.add(synthetic_vecs)\n",
    "    print(f\"FAISS Load & Indexing OK: {index.ntotal} vectors indexed.\")\n",
    "except Exception as e:\n",
    "    print(f\"Retrieval Indexing FAILED: {e}\")\n",
    "\n",
    "# 5. Metric Check (Evaluation)\n",
    "print(\"\\n--- Evaluation Metrics Check ---\")\n",
    "try:\n",
    "    _ = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
    "    _ = evaluate.load(\"bertscore\")\n",
    "    _ = sacrebleu.corpus_bleu([\"test\"], [[\"test\"]]) # Simple sacreBLEU call\n",
    "    print(\"All Evaluation Metrics (ROUGE, BERTScore, sacreBLEU) Load OK.\")\n",
    "except Exception as e:\n",
    "    print(f\"Metric Loading FAILED: {e}\")\n",
    "\n",
    "print(\"\\nALL PROJECT COMPONENTS READY ✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4f89cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medquad_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
