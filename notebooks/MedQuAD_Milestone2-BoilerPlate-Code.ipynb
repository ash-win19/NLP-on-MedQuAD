{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ebfc330",
   "metadata": {
    "id": "3ebfc330"
   },
   "source": [
    "# MedQuAD — Milestone 2 Progress Notebook (End-to-End)\n",
    "This notebook parses MedQuAD XML, performs EDA, creates leak-safe splits, and provides runnable baselines for:\n",
    "1) **Abstractive Answer Generation** (T5)  \n",
    "2) **Paraphrase Detection** (Siamese encoder)  \n",
    "3) **Retrieval-Augmented QA (RAG)** with BM25 + FAISS + Generator\n",
    "\n",
    "**Usage**\n",
    "1. Clone the dataset: `git clone https://github.com/abachaa/MedQuAD`\n",
    "2. Set `MEDQUAD_ROOT` below to that path.\n",
    "3. Run cells in order. Heavy training cells are commented for quick tests; uncomment on GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ec55e09",
   "metadata": {
    "id": "7ec55e09"
   },
   "outputs": [],
   "source": [
    "# Optional: install dependencies in a fresh environment\n",
    "# !pip install -q lxml pandas scikit-learn sentence-transformers transformers datasets evaluate rank-bm25 faiss-cpu nltk matplotlib seaborn rouge-score\n",
    "\n",
    "import os, re, glob, warnings\n",
    "from urllib.parse import urlparse\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 👉 EDIT THIS PATH to your local MedQuAD clone (e.g., '/content/MedQuAD' in Colab)\n",
    "MEDQUAD_ROOT = \"/Users/ashwinshanmugam/Documents/UIUC/University Courses/Fall 2025/IS 567 Text Mining/Project/NLP-on-MedQuAD/data\"\n",
    "OUT_DIR = \"./artifacts-medquad\"; os.makedirs(OUT_DIR, exist_ok=True)\n",
    "MEDQUAD_PARQUET = os.path.join(OUT_DIR, \"medquad.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c90f674",
   "metadata": {
    "id": "1c90f674"
   },
   "source": [
    "## 1) Ingest MedQuAD XML → tidy DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90184d90",
   "metadata": {
    "id": "90184d90",
    "outputId": "b231de61-f872-4d97-bf1b-cea77964cdee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Forcing re-parsing of MedQuAD XML to apply exclusion filters.\n",
      "The old medquad.parquet file will be overwritten with the filtered data.\n",
      "\n",
      "--- NEW DATASET SUMMARY ---\n",
      "Total Curated QA Pairs Stored in df: 16407\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>source</th>\n",
       "      <th>url</th>\n",
       "      <th>host</th>\n",
       "      <th>focus</th>\n",
       "      <th>focus_cui</th>\n",
       "      <th>focus_sem_type</th>\n",
       "      <th>focus_sem_group</th>\n",
       "      <th>pid</th>\n",
       "      <th>qid</th>\n",
       "      <th>qtype</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>xml_path</th>\n",
       "      <th>q_len</th>\n",
       "      <th>a_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000559</td>\n",
       "      <td>GHR</td>\n",
       "      <td>https://ghr.nlm.nih.gov/condition/keratoderma-...</td>\n",
       "      <td>ghr.nlm.nih.gov</td>\n",
       "      <td>keratoderma with woolly hair</td>\n",
       "      <td>C0343073</td>\n",
       "      <td>T047</td>\n",
       "      <td>Disorders</td>\n",
       "      <td>1</td>\n",
       "      <td>0000559-1</td>\n",
       "      <td>information</td>\n",
       "      <td>What is (are) keratoderma with woolly hair ?</td>\n",
       "      <td>Keratoderma with woolly hair is a group of rel...</td>\n",
       "      <td>/Users/ashwinshanmugam/Documents/UIUC/Universi...</td>\n",
       "      <td>8</td>\n",
       "      <td>290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000559</td>\n",
       "      <td>GHR</td>\n",
       "      <td>https://ghr.nlm.nih.gov/condition/keratoderma-...</td>\n",
       "      <td>ghr.nlm.nih.gov</td>\n",
       "      <td>keratoderma with woolly hair</td>\n",
       "      <td>C0343073</td>\n",
       "      <td>T047</td>\n",
       "      <td>Disorders</td>\n",
       "      <td>2</td>\n",
       "      <td>0000559-2</td>\n",
       "      <td>frequency</td>\n",
       "      <td>How many people are affected by keratoderma wi...</td>\n",
       "      <td>Keratoderma with woolly hair is rare; its prev...</td>\n",
       "      <td>/Users/ashwinshanmugam/Documents/UIUC/Universi...</td>\n",
       "      <td>11</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000559</td>\n",
       "      <td>GHR</td>\n",
       "      <td>https://ghr.nlm.nih.gov/condition/keratoderma-...</td>\n",
       "      <td>ghr.nlm.nih.gov</td>\n",
       "      <td>keratoderma with woolly hair</td>\n",
       "      <td>C0343073</td>\n",
       "      <td>T047</td>\n",
       "      <td>Disorders</td>\n",
       "      <td>3</td>\n",
       "      <td>0000559-3</td>\n",
       "      <td>genetic changes</td>\n",
       "      <td>What are the genetic changes related to kerato...</td>\n",
       "      <td>Mutations in the JUP, DSP, DSC2, and KANK2 gen...</td>\n",
       "      <td>/Users/ashwinshanmugam/Documents/UIUC/Universi...</td>\n",
       "      <td>12</td>\n",
       "      <td>284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    doc_id source                                                url  \\\n",
       "0  0000559    GHR  https://ghr.nlm.nih.gov/condition/keratoderma-...   \n",
       "1  0000559    GHR  https://ghr.nlm.nih.gov/condition/keratoderma-...   \n",
       "2  0000559    GHR  https://ghr.nlm.nih.gov/condition/keratoderma-...   \n",
       "\n",
       "              host                         focus focus_cui focus_sem_type  \\\n",
       "0  ghr.nlm.nih.gov  keratoderma with woolly hair  C0343073           T047   \n",
       "1  ghr.nlm.nih.gov  keratoderma with woolly hair  C0343073           T047   \n",
       "2  ghr.nlm.nih.gov  keratoderma with woolly hair  C0343073           T047   \n",
       "\n",
       "  focus_sem_group pid        qid            qtype  \\\n",
       "0       Disorders   1  0000559-1      information   \n",
       "1       Disorders   2  0000559-2        frequency   \n",
       "2       Disorders   3  0000559-3  genetic changes   \n",
       "\n",
       "                                            question  \\\n",
       "0       What is (are) keratoderma with woolly hair ?   \n",
       "1  How many people are affected by keratoderma wi...   \n",
       "2  What are the genetic changes related to kerato...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  Keratoderma with woolly hair is a group of rel...   \n",
       "1  Keratoderma with woolly hair is rare; its prev...   \n",
       "2  Mutations in the JUP, DSP, DSC2, and KANK2 gen...   \n",
       "\n",
       "                                            xml_path  q_len  a_len  \n",
       "0  /Users/ashwinshanmugam/Documents/UIUC/Universi...      8    290  \n",
       "1  /Users/ashwinshanmugam/Documents/UIUC/Universi...     11     80  \n",
       "2  /Users/ashwinshanmugam/Documents/UIUC/Universi...     12    284  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_medquad_repo(repo_root):\n",
    "    # These are the directory names corresponding to the non-curated subsets.\n",
    "    EXCLUDE_DIRS = [\n",
    "        \"10_MPlus_ADAM_QA\",          # A.D.A.M. Medical Encyclopedia\n",
    "        \"11_MPlusDrugs_QA\",          # MedlinePlus Drug information\n",
    "        \"12_MPlusHerbsSupplements_QA\" # MedlinePlus Herbal medicine and supplement information\n",
    "    ]\n",
    "    rows = []\n",
    "\n",
    "    # Iterate through all XML files recursively\n",
    "    for xml_path in glob.glob(os.path.join(repo_root, \"**\", \"*.xml\"), recursive=True):\n",
    "\n",
    "        # --- NEW CODE: Check if the path contains an excluded directory name ---\n",
    "        if any(f\"/{d}/\" in xml_path for d in EXCLUDE_DIRS):\n",
    "             continue # Skip this XML file and move to the next one\n",
    "        # --- END NEW CODE ---\n",
    "\n",
    "        try:\n",
    "            tree = ET.parse(xml_path)\n",
    "        except Exception as e:\n",
    "            print(\"Parse error:\", xml_path, e); continue\n",
    "\n",
    "        root = tree.getroot()\n",
    "        doc_id = root.attrib.get(\"id\")\n",
    "        source = root.attrib.get(\"source\")\n",
    "        url = root.attrib.get(\"url\"); host = urlparse(url).netloc if url else None\n",
    "        focus = (root.findtext(\"./Focus\") or \"\").strip()\n",
    "        cui = root.findtext(\"./FocusAnnotations/UMLS/CUIs/CUI\")\n",
    "        sem_type = root.findtext(\"./FocusAnnotations/UMLS/SemanticTypes/SemanticType\")\n",
    "        sem_group = root.findtext(\"./FocusAnnotations/UMLS/SemanticGroup\")\n",
    "\n",
    "        for qa in root.findall(\"./QAPairs/QAPair\"):\n",
    "            pid = qa.attrib.get(\"pid\")\n",
    "            q = qa.find(\"./Question\"); a = qa.find(\"./Answer\")\n",
    "            qid = q.attrib.get(\"qid\") if q is not None else None\n",
    "            qtype = q.attrib.get(\"qtype\") if q is not None else None\n",
    "            question = (q.text or \"\").strip() if q is not None else \"\"\n",
    "            answer = (a.text or \"\").strip() if a is not None else \"\"\n",
    "\n",
    "            # Normalization (Whitespace cleanup)\n",
    "            question = re.sub(r\"\\s+\", \" \", question)\n",
    "            answer = re.sub(r\"\\s+\", \" \", answer)\n",
    "\n",
    "            # --- FINAL FILTER: Skip if answer is confirmed blank (for safety) ---\n",
    "            if not answer.strip():\n",
    "                 continue\n",
    "\n",
    "            rows.append(dict(doc_id=doc_id, source=source, url=url, host=host,\n",
    "                             focus=focus, focus_cui=cui, focus_sem_type=sem_type, focus_sem_group=sem_group,\n",
    "                             pid=pid, qid=qid, qtype=qtype, question=question, answer=answer, xml_path=xml_path))\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# First, ensure the directory exists for saving the new file\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "print(\"WARNING: Forcing re-parsing of MedQuAD XML to apply exclusion filters.\")\n",
    "print(\"The old medquad.parquet file will be overwritten with the filtered data.\")\n",
    "\n",
    "# 1. CALL THE FUNCTION, APPLYING THE NEW FILTERS\n",
    "df = parse_medquad_repo(MEDQUAD_ROOT)\n",
    "\n",
    "# 2. Add Length Columns for final filtering and EDA (This prevents the old KeyError)\n",
    "df[\"q_len\"] = df[\"question\"].str.split().str.len()\n",
    "df[\"a_len\"] = df[\"answer\"].str.split().str.len()\n",
    "\n",
    "# 3. Apply the final content filter (optional but safe)\n",
    "df = df[df['a_len'] > 0].copy()\n",
    "\n",
    "# 4. OVERWRITE AND SAVE THE NEW, CLEANED DATASET\n",
    "df.to_parquet(MEDQUAD_PARQUET)\n",
    "\n",
    "print(\"\\n--- NEW DATASET SUMMARY ---\")\n",
    "print(f\"Total Curated QA Pairs Stored in df: {len(df)}\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1e865a",
   "metadata": {
    "id": "2a1e865a"
   },
   "source": [
    "## 2) Quick EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6359e117",
   "metadata": {
    "id": "6359e117",
    "outputId": "122840c8-0896-40aa-8cba-fdb832a9551c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top sources:\n",
      " source             host                     \n",
      "GHR                ghr.nlm.nih.gov              5430\n",
      "GARD               rarediseases.info.nih.gov    5389\n",
      "NIDDK              www.niddk.nih.gov            1192\n",
      "NINDS              www.ninds.nih.gov            1088\n",
      "MPlusHealthTopics  www.nlm.nih.gov               981\n",
      "NIHSeniorHealth    nihseniorhealth.gov           769\n",
      "CancerGov          www.cancer.gov                729\n",
      "NHLBI              www.nhlbi.nih.gov             559\n",
      "CDC                www.cdc.gov                   270\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Top question types:\n",
      " qtype\n",
      "information        4535\n",
      "symptoms           2748\n",
      "treatment          2442\n",
      "inheritance        1446\n",
      "frequency          1120\n",
      "genetic changes    1087\n",
      "causes              727\n",
      "exams and tests     653\n",
      "research            395\n",
      "outlook             361\n",
      "susceptibility      324\n",
      "considerations      235\n",
      "prevention          210\n",
      "stages               77\n",
      "complications        46\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns, matplotlib.pyplot as plt\n",
    "sns.set_theme()\n",
    "\n",
    "print(\"Top sources:\\n\", df[[\"source\",\"host\"]].value_counts().head(10))\n",
    "print(\"\\nTop question types:\\n\", df[\"qtype\"].value_counts().head(15))\n",
    "\n",
    "df[\"q_len\"] = df[\"question\"].str.split().str.len()\n",
    "df[\"a_len\"] = df[\"answer\"].str.split().str.len()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sns.kdeplot(df[\"q_len\"].clip(0,300), label=\"question\", ax=ax)\n",
    "sns.kdeplot(df[\"a_len\"].clip(0,600), label=\"answer\", ax=ax)\n",
    "ax.set_title(\"Token-length distributions\")\n",
    "ax.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67f02ad",
   "metadata": {
    "id": "e67f02ad"
   },
   "source": [
    "## 3) Leak-safe train/dev/test splits (grouped by CUI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88936232",
   "metadata": {
    "id": "88936232",
    "outputId": "69c5ec68-20ca-4331-dd14-5ec5a7983fa3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12850, 1739, 1818)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "def make_splits(df, group_col=\"focus_cui\", seed=42):\n",
    "    df = df.copy()\n",
    "    groups = df[group_col].fillna(df[\"focus\"]).fillna(\"NOFOCUS\")\n",
    "    gss = GroupShuffleSplit(n_splits=1, train_size=0.8, random_state=seed)\n",
    "    train_idx, temp_idx = next(gss.split(df, groups=groups))\n",
    "    train = df.iloc[train_idx]; temp = df.iloc[temp_idx]\n",
    "    gss2 = GroupShuffleSplit(n_splits=1, train_size=0.5, random_state=seed)\n",
    "    dev_idx, test_idx = next(gss2.split(temp, groups=temp[group_col].fillna(temp[\"focus\"]).fillna(\"NOFOCUS\")))\n",
    "    dev = temp.iloc[dev_idx]; test = temp.iloc[test_idx]\n",
    "    return train, dev, test\n",
    "\n",
    "train_df, dev_df, test_df = make_splits(df)\n",
    "len(train_df), len(dev_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62e3649",
   "metadata": {
    "id": "a62e3649",
    "outputId": "0c18ae52-ebb4-45c9-fc0c-1d69510c4755"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total QA Pairs Parsed: 16407\n",
      "Rows with Blank Question/Answer: 0\n",
      "\n",
      "Sample of Cleaned Answer Lengths (words):\n",
      "count    16407.000000\n",
      "mean       201.354361\n",
      "std        248.480189\n",
      "min          1.000000\n",
      "25%         71.000000\n",
      "50%        138.000000\n",
      "75%        252.000000\n",
      "max       4281.000000\n",
      "Name: a_len, dtype: float64\n",
      "\n",
      "Number of QA Pairs with 1-3 Word Answers: 1\n",
      "Example of a very short answer: [['How to prevent Acanthamoeba - Granulomatous Amebic Encephalitis (GAE); Keratitis ?'\n",
      "  'Topics']]\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have run the XML parsing (Cell 4) to create 'df'\n",
    "\n",
    "# Check the number of rows that had blank answers *before* dropping them:\n",
    "total_rows = len(df)\n",
    "valid_rows = len(df.dropna(subset=['question', 'answer']))\n",
    "rows_with_missing_data = total_rows - valid_rows\n",
    "\n",
    "print(f\"Total QA Pairs Parsed: {total_rows}\")\n",
    "print(f\"Rows with Blank Question/Answer: {rows_with_missing_data}\")\n",
    "\n",
    "# Display a sample of the cleaned-up answers to check for quality\n",
    "print(\"\\nSample of Cleaned Answer Lengths (words):\")\n",
    "print(df['a_len'].describe())\n",
    "\n",
    "# Check for rows where the answer might be very short (e.g., just punctuation)\n",
    "short_answers = df[df['a_len'].between(1, 3)]\n",
    "print(f\"\\nNumber of QA Pairs with 1-3 Word Answers: {len(short_answers)}\")\n",
    "if not short_answers.empty:\n",
    "    print(\"Example of a very short answer:\", short_answers[['question', 'answer']].head(1).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d42c378",
   "metadata": {
    "id": "6d42c378"
   },
   "source": [
    "## 4) Task 1 — Abstractive Answer Generation (T5-small baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1c5a72",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "9d68f0c087734204864370691c68df71",
      "16499ac23d68413b97d87ee4863942d4",
      "4e140a8f1e184bc38567377a7ac2ff3d"
     ]
    },
    "id": "9c1c5a72",
    "outputId": "16cb1ee5-1275-496b-aab0-1260f3c90440"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d68f0c087734204864370691c68df71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12850 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16499ac23d68413b97d87ee4863942d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1739 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e140a8f1e184bc38567377a7ac2ff3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1818 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import T5ForConditionalGeneration, T5TokenizerFast, DataCollatorForSeq2Seq, Trainer, TrainingArguments\n",
    "from evaluate import load as load_metric\n",
    "import numpy as np, torch\n",
    "\n",
    "def build_hf_dataset(train_df, dev_df, test_df, max_input=512, max_target=512):\n",
    "    def to_ds(frame):\n",
    "        sub = frame[[\"question\",\"answer\"]].dropna().rename(columns={\"question\":\"input_text\",\"answer\":\"target_text\"})\n",
    "        return Dataset.from_pandas(sub)\n",
    "    raw = DatasetDict(train=to_ds(train_df), validation=to_ds(dev_df), test=to_ds(test_df))\n",
    "    tok = T5TokenizerFast.from_pretrained(\"t5-small\")\n",
    "    def preprocess(ex):\n",
    "        ex[\"input_ids\"] = tok(\"question: \" + ex[\"input_text\"], truncation=True, max_length=max_input).input_ids\n",
    "        ex[\"labels\"]    = tok(ex[\"target_text\"], truncation=True, max_length=max_target).input_ids\n",
    "        return ex\n",
    "    tokenized = raw.map(preprocess, remove_columns=raw[\"train\"].column_names)\n",
    "    return tokenized, tok\n",
    "\n",
    "tokenized, tok = build_hf_dataset(train_df, dev_df, test_df)\n",
    "\n",
    "def train_t5(tokenized, tok, out_dir=\"./t5-medquad\"):\n",
    "    model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "    collator = DataCollatorForSeq2Seq(tok, model=model)\n",
    "    args = TrainingArguments(\n",
    "        output_dir=out_dir, per_device_train_batch_size=2, per_device_eval_batch_size=2,\n",
    "        learning_rate=3e-4, num_train_epochs=5, fp16=False, eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\", logging_steps=50, report_to=\"none\"\n",
    "    )\n",
    "    trainer = Trainer(model=model, args=args, data_collator=collator,\n",
    "                      train_dataset=tokenized[\"train\"], eval_dataset=tokenized[\"validation\"])\n",
    "    trainer.train()\n",
    "    return trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa898e3",
   "metadata": {
    "id": "faa898e3"
   },
   "outputs": [],
   "source": [
    "# Clear Memory Cache\n",
    "torch.mps.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74943817",
   "metadata": {
    "id": "74943817",
    "outputId": "939d1e28-dfe6-4045-c55f-befbb8f4b6ea"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32125' max='32125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32125/32125 2:30:50, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.337900</td>\n",
       "      <td>2.155518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.184300</td>\n",
       "      <td>2.031071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.046900</td>\n",
       "      <td>1.971100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.822500</td>\n",
       "      <td>1.938025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.786200</td>\n",
       "      <td>1.926317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = train_t5(tokenized, tok)   # ← Uncomment to train\n",
    "trainer.save_model(\"./t5-medquad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d35eb8",
   "metadata": {
    "id": "e3d35eb8"
   },
   "outputs": [],
   "source": [
    "def eval_generation(model_dir, tokenized, tok):\n",
    "    # This function is assumed to be run after the model has been trained and saved to model_dir\n",
    "    import torch, numpy as np\n",
    "    from evaluate import load as load_metric\n",
    "    from transformers import T5ForConditionalGeneration # Note: Use AutoModelForSeq2SeqLM if using BioBART\n",
    "\n",
    "    rouge = load_metric(\"rouge\")\n",
    "    bertscore = load_metric(\"bertscore\")\n",
    "\n",
    "    # Load the model and ensure it uses the M4 GPU\n",
    "    model = T5ForConditionalGeneration.from_pretrained(model_dir)\n",
    "    DEVICE = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    # Select a subset of the test data (e.g., 256 examples)\n",
    "    test = tokenized[\"test\"].select(range(min(256, len(tokenized[\"test\"]))))\n",
    "\n",
    "    # --- Generation Logic (Assumed Correct and Working) ---\n",
    "    input_ids_list = test[\"input_ids\"]\n",
    "    padded_inputs = tok.pad(\n",
    "        {'input_ids': input_ids_list},\n",
    "        return_tensors=\"pt\"\n",
    "    ).input_ids.to(DEVICE)\n",
    "\n",
    "    preds = model.generate(padded_inputs, max_new_tokens=256)\n",
    "\n",
    "    pred_text = tok.batch_decode(preds, skip_special_tokens=True)\n",
    "    ref_text  = tok.batch_decode(test[\"labels\"], skip_special_tokens=True)\n",
    "\n",
    "    # --- Metrics Calculation ---\n",
    "    r = rouge.compute(predictions=pred_text, references=ref_text, use_stemmer=True)\n",
    "    b = bertscore.compute(predictions=pred_text, references=ref_text, lang=\"en\")\n",
    "\n",
    "    # FINAL FIX: Access the ROUGE-L score directly as the key's value.\n",
    "    print(\"ROUGE-L:\", r[\"rougeL\"], \" BERTScore(F1):\", float(np.mean(b[\"f1\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f289cd50-a072-4dda-9924-389043271e0f",
   "metadata": {
    "id": "f289cd50-a072-4dda-9924-389043271e0f",
    "outputId": "928dcfe4-8ab0-411a-cab3-18031ebb9121"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-L: 0.4064322101893944  BERTScore(F1): 0.884045472368598\n"
     ]
    }
   ],
   "source": [
    "# Assuming your trained model was saved to the T5 folder as planned\n",
    "# NOTE: If you trained BioBART, you must change the directory name.\n",
    "\n",
    "eval_generation(\n",
    "    model_dir=\"./t5-medquad\",     # The directory where trainer.save_model() stored the weights\n",
    "    tokenized=tokenized,          # The DatasetDict containing the 'test' set\n",
    "    tok=tok                       # The T5TokenizerFast object\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbb07bb-e9ac-4b3c-b326-5975e8faaee9",
   "metadata": {
    "id": "efbb07bb-e9ac-4b3c-b326-5975e8faaee9",
    "outputId": "0133e334-3f17-4cfb-abf6-6e6070ad8422"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qualitative Results (Top 10 Examples):\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Candidate_Answer</th>\n",
       "      <th>Reference_Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is (are) keratoderma with woolly hair?</td>\n",
       "      <td>Keratoderma with woolly hair is a skin conditi...</td>\n",
       "      <td>Keratoderma with woolly hair is a group of rel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How many people are affected by keratoderma wi...</td>\n",
       "      <td>Keratoderma with woolly hair is a rare conditi...</td>\n",
       "      <td>Keratoderma with woolly hair is rare; its prev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are the genetic changes related to kerato...</td>\n",
       "      <td>Keratoderma with woolly hair is caused by muta...</td>\n",
       "      <td>Mutations in the JUP, DSP, DSC2, and KANK2 gen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Is keratoderma with woolly hair inherited?</td>\n",
       "      <td>This condition is inherited in an autosomal re...</td>\n",
       "      <td>Most cases of keratoderma with woolly hair hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are the treatments for keratoderma with w...</td>\n",
       "      <td>These resources address the diagnosis or manag...</td>\n",
       "      <td>These resources address the diagnosis or manag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What is (are) trisomy 18?</td>\n",
       "      <td>Trisomy 18 is an inherited disorder that affec...</td>\n",
       "      <td>Trisomy 18, also called Edwards syndrome, is a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How many people are affected by trisomy 18?</td>\n",
       "      <td>Trisomy 18 is a rare disorder; its prevalence ...</td>\n",
       "      <td>Trisomy 18 occurs in about 1 in 5,000 live-bor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What are the genetic changes related to trisom...</td>\n",
       "      <td>Trisomy 18 is caused by mutations in the COL1A...</td>\n",
       "      <td>Most cases of trisomy 18 result from having th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Is trisomy 18 inherited?</td>\n",
       "      <td>This condition is inherited in an autosomal re...</td>\n",
       "      <td>Most cases of trisomy 18 are not inherited, bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What are the treatments for trisomy 18?</td>\n",
       "      <td>These resources address the diagnosis or manag...</td>\n",
       "      <td>These resources address the diagnosis or manag...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0        What is (are) keratoderma with woolly hair?   \n",
       "1  How many people are affected by keratoderma wi...   \n",
       "2  What are the genetic changes related to kerato...   \n",
       "3         Is keratoderma with woolly hair inherited?   \n",
       "4  What are the treatments for keratoderma with w...   \n",
       "5                          What is (are) trisomy 18?   \n",
       "6        How many people are affected by trisomy 18?   \n",
       "7  What are the genetic changes related to trisom...   \n",
       "8                           Is trisomy 18 inherited?   \n",
       "9            What are the treatments for trisomy 18?   \n",
       "\n",
       "                                    Candidate_Answer  \\\n",
       "0  Keratoderma with woolly hair is a skin conditi...   \n",
       "1  Keratoderma with woolly hair is a rare conditi...   \n",
       "2  Keratoderma with woolly hair is caused by muta...   \n",
       "3  This condition is inherited in an autosomal re...   \n",
       "4  These resources address the diagnosis or manag...   \n",
       "5  Trisomy 18 is an inherited disorder that affec...   \n",
       "6  Trisomy 18 is a rare disorder; its prevalence ...   \n",
       "7  Trisomy 18 is caused by mutations in the COL1A...   \n",
       "8  This condition is inherited in an autosomal re...   \n",
       "9  These resources address the diagnosis or manag...   \n",
       "\n",
       "                                    Reference_Answer  \n",
       "0  Keratoderma with woolly hair is a group of rel...  \n",
       "1  Keratoderma with woolly hair is rare; its prev...  \n",
       "2  Mutations in the JUP, DSP, DSC2, and KANK2 gen...  \n",
       "3  Most cases of keratoderma with woolly hair hav...  \n",
       "4  These resources address the diagnosis or manag...  \n",
       "5  Trisomy 18, also called Edwards syndrome, is a...  \n",
       "6  Trisomy 18 occurs in about 1 in 5,000 live-bor...  \n",
       "7  Most cases of trisomy 18 result from having th...  \n",
       "8  Most cases of trisomy 18 are not inherited, bu...  \n",
       "9  These resources address the diagnosis or manag...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_qualitative_results(model_dir, tokenized, tok, num_examples=10):\n",
    "    \"\"\"\n",
    "    Loads the trained model, generates predictions, and returns a DataFrame\n",
    "    showing the Question, Model Answer, and Reference Answer.\n",
    "    \"\"\"\n",
    "    import torch\n",
    "    import pandas as pd\n",
    "    from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "    # 1. Load Model and Set Device\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_dir)\n",
    "    DEVICE = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    # 2. Select Test Subset (This is where the data is loaded)\n",
    "    test_subset = tokenized[\"test\"].select(range(num_examples))\n",
    "\n",
    "    # 3. Prepare Input IDs with Padding\n",
    "    input_ids_list = test_subset[\"input_ids\"]\n",
    "    padded_inputs = tok.pad(\n",
    "        {'input_ids': input_ids_list},\n",
    "        return_tensors=\"pt\"\n",
    "    ).input_ids.to(DEVICE)\n",
    "\n",
    "    # 4. Generate Predictions\n",
    "    preds = model.generate(\n",
    "        padded_inputs,\n",
    "        max_new_tokens=256,\n",
    "        num_beams=4,\n",
    "        do_sample=False\n",
    "    )\n",
    "\n",
    "    # 5. Decode Results (The Fix is here)\n",
    "    pred_text = tok.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    # --- FIX START: Restore Question Text from Tokens ---\n",
    "    # a. Decode the input tokens (which contain the text + \"question: \" prefix)\n",
    "    questions_with_prefix = tok.batch_decode(test_subset[\"input_ids\"], skip_special_tokens=True)\n",
    "    # b. Strip the \"question: \" prefix (T5 instruction) for a clean display\n",
    "    questions = [q.replace('question: ', '').strip() for q in questions_with_prefix]\n",
    "    # c. Decode the reference labels\n",
    "    ref_text  = tok.batch_decode(test_subset[\"labels\"], skip_special_tokens=True)\n",
    "    # --- FIX END ---\n",
    "\n",
    "    # 6. Compile and Return DataFrame\n",
    "    results_df = pd.DataFrame({\n",
    "        'Question': questions,\n",
    "        'Candidate_Answer': pred_text,\n",
    "        'Reference_Answer': ref_text\n",
    "    })\n",
    "    return results_df\n",
    "\n",
    "# --- EXECUTION ---\n",
    "# NOTE: Use \"./biobart-medquad\" if you trained the BioBART model.\n",
    "qual_df = get_qualitative_results(\n",
    "    model_dir=\"./t5-medquad\",\n",
    "    tokenized=tokenized,\n",
    "    tok=tok,\n",
    "    num_examples=10\n",
    ")\n",
    "\n",
    "print(f\"Qualitative Results (Top 10 Examples):\\n\")\n",
    "qual_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6319786",
   "metadata": {
    "id": "b6319786"
   },
   "source": [
    "## 5) Task 2 — Paraphrase Detection (Siamese baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfc3e33",
   "metadata": {
    "id": "fbfc3e33",
    "outputId": "acdf060f-5f52-4b04-c05a-dc6c0c996d2c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26280, 6570, np.float64(0.60882800608828))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def build_paraphrase_pairs(df, max_pos=20000, max_neg=20000, seed=13):\n",
    "    df2 = df.dropna(subset=[\"question\"]).copy()\n",
    "    pos = []\n",
    "    for cui, block in df2.groupby(df2[\"focus_cui\"].fillna(\"NOFOCUS\")):\n",
    "        qs = block[\"question\"].drop_duplicates().tolist()\n",
    "        for a,b in combinations(qs, 2):\n",
    "            pos.append((a,b,1))\n",
    "            if len(pos) >= max_pos: break\n",
    "        if len(pos) >= max_pos: break\n",
    "    a_list = df2[\"question\"].sample(min(max_neg, len(df2)), random_state=seed).tolist()\n",
    "    b_list = df2[\"question\"].sample(min(max_neg, len(df2)), random_state=seed+1).tolist()\n",
    "    neg = [(a,b,0) for a,b in zip(a_list,b_list) if a!=b][:max_neg]\n",
    "    pairs = pd.DataFrame(pos+neg, columns=[\"q1\",\"q2\",\"label\"]).sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "    return pairs\n",
    "\n",
    "pairs = build_paraphrase_pairs(train_df)\n",
    "pairs_train, pairs_dev = train_test_split(pairs, test_size=0.2, random_state=7, stratify=pairs[\"label\"])\n",
    "len(pairs_train), len(pairs_dev), pairs_train[\"label\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72a5947",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "14ae04db270d4f0b9ff6787b21cc006c"
     ]
    },
    "id": "d72a5947",
    "outputId": "64daae94-c9bb-44d3-8139-dbb9b190b48d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14ae04db270d4f0b9ff6787b21cc006c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='822' max='822' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [822/822 01:26, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.041200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from torch.utils.data import DataLoader\n",
    "import torch, numpy as np\n",
    "\n",
    "def train_siamese(pairs, model_name=\"sentence-transformers/all-MiniLM-L6-v2\", epochs=1):\n",
    "    model = SentenceTransformer(model_name)\n",
    "    train_ex = [InputExample(texts=[r.q1, r.q2], label=float(r.label)) for _,r in pairs.iterrows()]\n",
    "    loader = DataLoader(train_ex, shuffle=True, batch_size=32)\n",
    "    train_loss = losses.CosineSimilarityLoss(model)\n",
    "    model.fit(train_objectives=[(loader, train_loss)], epochs=epochs, warmup_steps=max(1, int(len(loader)*0.1)))\n",
    "    return model\n",
    "\n",
    "sbert = train_siamese(pairs_train)        # ← Uncomment to train\n",
    "sbert.save(\"./sbert-paraphrase-medquad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5414b8",
   "metadata": {
    "id": "6d5414b8",
    "outputId": "51c238af-55a7-4954-b97a-5dcb18879a15"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9894977168949771"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def eval_siamese(model_dir, eval_df, thresh=0.5):\n",
    "    model = SentenceTransformer(model_dir)\n",
    "    a = model.encode(eval_df[\"q1\"].tolist(), convert_to_tensor=True, show_progress_bar=False)\n",
    "    b = model.encode(eval_df[\"q2\"].tolist(), convert_to_tensor=True, show_progress_bar=False)\n",
    "    sims = torch.nn.functional.cosine_similarity(a,b).cpu().numpy()\n",
    "    preds = (sims >= thresh).astype(int)\n",
    "    acc = (preds == eval_df[\"label\"].values).mean()\n",
    "    return float(acc)\n",
    "\n",
    "eval_siamese(\"./sbert-paraphrase-medquad\", pairs_dev)  # ← Evaluate after training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbce330",
   "metadata": {
    "id": "2bbce330"
   },
   "source": [
    "## 6) Task 3 — Retrieval-Augmented QA (BM25 + FAISS + Generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a14d07",
   "metadata": {
    "id": "b2a14d07"
   },
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss, numpy as np, nltk\n",
    "nltk.download('punkt', quiet=True)\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "corpus = train_df[\"answer\"].dropna().tolist() + dev_df[\"answer\"].dropna().tolist()\n",
    "\n",
    "def build_bm25(corpus_texts):\n",
    "    tokenized = [word_tokenize(t.lower()) for t in corpus_texts]\n",
    "    return BM25Okapi(tokenized), tokenized\n",
    "\n",
    "bm25, tok_corp = build_bm25(corpus)\n",
    "\n",
    "def bm25_topk(bm25, tokenized_corpus, query, k=5):\n",
    "    scores = bm25.get_scores(word_tokenize(query.lower()))\n",
    "    idx = np.argsort(-scores)[:k]\n",
    "    return idx, scores[idx]\n",
    "\n",
    "def build_faiss(corpus_texts, embedder=\"sentence-transformers/all-MiniLM-L6-v2\"):\n",
    "    enc = SentenceTransformer(embedder)\n",
    "    vecs = enc.encode(corpus_texts, normalize_embeddings=True, show_progress_bar=False)\n",
    "    index = faiss.IndexFlatIP(vecs.shape[1]); index.add(vecs.astype(np.float32))\n",
    "    return enc, index, vecs\n",
    "\n",
    "enc, faiss_index, vecs = build_faiss(corpus)\n",
    "\n",
    "def dense_topk(enc, faiss_index, query, k=5):\n",
    "    qv = enc.encode([query], normalize_embeddings=True, show_progress_bar=False)\n",
    "    D, I = faiss_index.search(qv.astype(np.float32), k)\n",
    "    return I[0], D[0]\n",
    "\n",
    "def rag_context_for(question, k=5):\n",
    "    cand = set()\n",
    "    bi, _ = bm25_topk(bm25, tok_corp, question, k=k); cand.update(bi)\n",
    "    di, _ = dense_topk(enc, faiss_index, question, k=k); cand.update(di)\n",
    "    idxs = list(cand)[:k]\n",
    "    ctx = \" \".join([corpus[i] for i in idxs])\n",
    "    return ctx, idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec74e8a",
   "metadata": {
    "id": "2ec74e8a",
    "outputId": "037786bc-793d-4a92-db2d-3c3c34e3c7ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.31, 0.21233333333333337)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieval quality metrics via ROUGE-L vs gold answer\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "def retrieval_metrics(questions, gold_answers, k=5, rouge_thresh=0.2):\n",
    "    sc = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
    "    hits, rr = 0, 0.0\n",
    "    for q, gold in zip(questions, gold_answers):\n",
    "        idxs, _ = bm25_topk(bm25, tok_corp, q, k)\n",
    "        best_rank = None\n",
    "        for r, i in enumerate(idxs, start=1):\n",
    "            rougeL = sc.score(gold, corpus[i])['rougeL'].fmeasure\n",
    "            if rougeL >= rouge_thresh:\n",
    "                best_rank = r; break\n",
    "        if best_rank:\n",
    "            hits += 1; rr += 1.0 / best_rank\n",
    "    n = len(questions)\n",
    "    return hits / n, rr / n\n",
    "\n",
    "\n",
    "sample = test_df.dropna(subset=[\"question\",\"answer\"]).sample(200, random_state=7)\n",
    "recall_k, mrr = retrieval_metrics(sample[\"question\"].tolist(), sample[\"answer\"].tolist(), k=5)\n",
    "recall_k, mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0184317",
   "metadata": {
    "id": "b0184317",
    "outputId": "99a49d84-5c24-40dd-90b2-b3591a9039da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The symptoms of botulism are usually mild and may include a rash of swollen skin, rash, and rash. The most common symptoms of botulism are a rash of rash, rash, and rash. The rash of rash is usually a rash. The rash of rash is usually a rash. The rash of rash is usually a rash. The rash of rash is usually a rash. The rash of rash is usually accompanied by a rash of a rash. The\n"
     ]
    }
   ],
   "source": [
    "# RAG generation with T5\n",
    "from transformers import T5ForConditionalGeneration, T5TokenizerFast\n",
    "\n",
    "def rag_generate(model_dir, question, k=5, max_input=384, max_new=128):\n",
    "    tok = T5TokenizerFast.from_pretrained(\"t5-small\")\n",
    "    model = T5ForConditionalGeneration.from_pretrained(model_dir)\n",
    "    ctx, idxs = rag_context_for(question, k=k)\n",
    "    inp = f\"question: {question}  context: {ctx}\"\n",
    "    ids = tok(inp, return_tensors=\"pt\", truncation=True, max_length=max_input).input_ids\n",
    "    out = model.generate(ids, max_new_tokens=max_new)\n",
    "    return tok.decode(out[0], skip_special_tokens=True), idxs\n",
    "\n",
    "q = sample[\"question\"].iloc[0]; pred, idxs = rag_generate(\"./t5-medquad\", q); print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851f4d86",
   "metadata": {
    "id": "851f4d86"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def save_df_to_csv(df, file_name=\"medquad_qa_check.csv\"):\n",
    "    \"\"\"\n",
    "    Saves the current DataFrame to a CSV file in the OUT_DIR.\n",
    "    \"\"\"\n",
    "    csv_path = os.path.join(OUT_DIR, file_name)\n",
    "\n",
    "    # Save only the columns needed for verification, including the length columns\n",
    "    df[['question', 'answer', 'q_len', 'a_len', 'source', 'host', 'xml_path']].to_csv(csv_path, index=False)\n",
    "\n",
    "    print(f\"DataFrame successfully saved to: {csv_path}\")\n",
    "    print(\"Check the 'a_len' column in the CSV for zero values.\")\n",
    "\n",
    "# Example Usage (Run this cell after running Cell 5/EDA)\n",
    "# You should have defined OUT_DIR in an earlier cell.\n",
    "save_df_to_csv(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e332b2f7",
   "metadata": {
    "id": "e332b2f7"
   },
   "outputs": [],
   "source": [
    "df_filtered = df[df['a_len'] > 0].copy()\n",
    "df_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e45328f",
   "metadata": {
    "id": "5e45328f"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm.notebook import tqdm # Use the notebook tqdm for progress bars\n",
    "\n",
    "# Headers mimic a standard browser to avoid being blocked by the server\n",
    "HEADERS = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
    "\n",
    "def crawl_url_for_answer(url):\n",
    "    \"\"\"Fetches a URL and attempts to extract a large, coherent block of text.\"\"\"\n",
    "    if not url or not url.startswith('http'):\n",
    "        return None\n",
    "    try:\n",
    "        response = requests.get(url, headers=HEADERS, timeout=10)\n",
    "        response.raise_for_status() # Raise exception for bad status codes\n",
    "\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # --- Heuristics to find relevant content on NIH-style pages ---\n",
    "        # Look for the main content area (often div with id/class that indicates content)\n",
    "        # These are common selectors for the main text body:\n",
    "        main_content = soup.find('article') or soup.find('main') or soup.find('div', id=lambda x: x and 'content' in x.lower())\n",
    "\n",
    "        if main_content:\n",
    "            # Extract and clean all paragraph text from the main body\n",
    "            text = ' '.join(p.get_text() for p in main_content.find_all('p'))\n",
    "            # Simple cleaning\n",
    "            cleaned_text = re.sub(r'\\s+', ' ', text).strip()\n",
    "            # If the extracted text is very short, it's probably wrong.\n",
    "            if len(cleaned_text.split()) > 50:\n",
    "                return cleaned_text\n",
    "\n",
    "        return None\n",
    "    except requests.RequestException as e:\n",
    "        # print(f\"Error crawling {url}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1fa89b",
   "metadata": {
    "id": "ce1fa89b"
   },
   "outputs": [],
   "source": [
    "# 1. Ensure you have run the fix for the previous turn to get a_len\n",
    "df[\"a_len\"] = df[\"answer\"].str.split().str.len()\n",
    "\n",
    "# 2. Filter the DataFrame to isolate ONLY the rows with missing answers (a_len == 0)\n",
    "missing_answers_df = df[df['a_len'] == 0].copy()\n",
    "\n",
    "# 3. Create a new column to store the crawled answers\n",
    "missing_answers_df['crawled_answer'] = None\n",
    "\n",
    "# 4. Loop through the missing rows and crawl each URL\n",
    "tqdm.pandas(desc=\"Crawling Missing Answers\")\n",
    "missing_answers_df['crawled_answer'] = missing_answers_df['url'].progress_apply(crawl_url_for_answer)\n",
    "\n",
    "# 5. Filter for successful results\n",
    "crawled_results_df = missing_answers_df.dropna(subset=['crawled_answer'])\n",
    "\n",
    "print(f\"Successfully crawled and extracted answers for {len(crawled_results_df)} of {len(missing_answers_df)} questions.\")\n",
    "crawled_results_df[['question', 'crawled_answer', 'url']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c490cf20-edbf-4651-a7cc-ca5d83ec62fc",
   "metadata": {
    "id": "c490cf20-edbf-4651-a7cc-ca5d83ec62fc"
   },
   "outputs": [],
   "source": [
    "# ==== CONFIG ====\n",
    "LOCAL_PUBMED = \"/Users/harshasekar/Documents/UIUC/IS-567 Text Mining/Project/Code_V1/Models/S-PubMedBert-MS-MARCO\"\n",
    "\n",
    "USE_CHUNKING = True          # ← flip this to False for non-chunked run\n",
    "CHUNK_MAX_TOKENS = 160       # good balance for SBERT encoders\n",
    "CHUNK_STRIDE     = 80        # 50% overlap\n",
    "MAX_CHUNKS_PER_ANSWER = 3    # cap to control runtime (set None for unlimited)\n",
    "\n",
    "EVAL_K = 10                  # Recall@K / MRR@K\n",
    "POOL_N = 50                  # candidate pool size for hybrid fusion\n",
    "\n",
    "# ==== HELPERS ====\n",
    "import time, re, numpy as np, random\n",
    "from collections import defaultdict\n",
    "\n",
    "def tic(msg):\n",
    "    print(f\"\\n⏱️ {msg} ...\", flush=True);\n",
    "    return time.time()\n",
    "\n",
    "def toc(t0, msg=\"done\"):\n",
    "    print(f\"✅ {msg} in {time.time()-t0:.2f}s\", flush=True)\n",
    "\n",
    "def preview(txt, n=120):\n",
    "    return str(txt).replace(\"\\n\", \" \")[:n]\n",
    "\n",
    "random.seed(13); np.random.seed(13)\n",
    "\n",
    "# Basic checks\n",
    "assert {\"question\",\"answer\"}.issubset(train_df.columns)\n",
    "assert {\"question\",\"answer\"}.issubset(dev_df.columns)\n",
    "assert {\"question\",\"answer\"}.issubset(test_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edb595f-71cd-41b4-85fe-ab4d46ae7ae0",
   "metadata": {
    "id": "9edb595f-71cd-41b4-85fe-ab4d46ae7ae0",
    "outputId": "0c81fa5b-4137-49a0-876d-198b0a16b085"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⏱️ Building full passage corpus ...\n",
      "✅ Built 16407 full passages in 0.22s\n",
      "• Passage[0]: Knobloch syndrome is a rare condition characterized by severe vision problems and a skull defect. A characteristic featu ...\n",
      "• Passage[1]: Knobloch syndrome is a rare condition. However, the exact prevalence of the condition is unknown. ...\n",
      "\n",
      "⏱️ Building CHUNKED corpus ...\n",
      "✅ Chunked to 28148 passages (~1.7/answer) in 0.28s\n",
      "• Chunk[0] → Answer[0]: knobloch syndrome is a rare condition characterized by severe vision problems and a skull defect a characteristic featur ...\n",
      "• Chunk[1] → Answer[0]: at the back of the eye vitreoretinal degeneration often leads to separation of the retina from the back of the eye retin ...\n"
     ]
    }
   ],
   "source": [
    "# Full answers (no truncation)\n",
    "passages, passage_meta = [], []\n",
    "def _add(df, split):\n",
    "    for _, r in df.iterrows():\n",
    "        passages.append(str(r[\"answer\"]))\n",
    "        passage_meta.append({\"split\": split})\n",
    "\n",
    "t0 = tic(\"Building full passage corpus\")\n",
    "_add(train_df, \"train\"); _add(dev_df, \"dev\"); _add(test_df, \"test\")\n",
    "toc(t0, f\"Built {len(passages)} full passages\")\n",
    "for i in range(min(2, len(passages))):\n",
    "    print(f\"• Passage[{i}]: {preview(passages[i])} ...\")\n",
    "\n",
    "# Optional chunked corpus\n",
    "chunk_passages, chunk2orig_idx = None, None\n",
    "if USE_CHUNKING:\n",
    "    def _tokens(text): return re.findall(r\"[A-Za-z0-9]+\", str(text).lower())\n",
    "    def _chunk_words(text, max_tokens=CHUNK_MAX_TOKENS, stride=CHUNK_STRIDE):\n",
    "        toks = _tokens(text)\n",
    "        if not toks: return [str(text)]\n",
    "        out, i = [], 0\n",
    "        while i < len(toks):\n",
    "            out.append(\" \".join(toks[i:i+max_tokens]))\n",
    "            if i + max_tokens >= len(toks): break\n",
    "            i += stride\n",
    "        return out\n",
    "\n",
    "    t1 = tic(\"Building CHUNKED corpus\")\n",
    "    chunk_passages, chunk2orig_idx = [], []\n",
    "    for orig_idx, full in enumerate(passages):\n",
    "        chunks = _chunk_words(full)\n",
    "        if MAX_CHUNKS_PER_ANSWER is not None:\n",
    "            chunks = chunks[:MAX_CHUNKS_PER_ANSWER]\n",
    "        for ch in chunks:\n",
    "            chunk_passages.append(ch)\n",
    "            chunk2orig_idx.append(orig_idx)\n",
    "    toc(t1, f\"Chunked to {len(chunk_passages)} passages (~{len(chunk_passages)/max(1,len(passages)):.1f}/answer)\")\n",
    "    for i in range(min(2, len(chunk_passages))):\n",
    "        print(f\"• Chunk[{i}] → Answer[{chunk2orig_idx[i]}]: {preview(chunk_passages[i])} ...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8c7261-069e-4914-b646-b881efbda6ba",
   "metadata": {
    "id": "3b8c7261-069e-4914-b646-b881efbda6ba",
    "outputId": "ea1eef12-52c6-4f03-c7e5-f61c0eee8c0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[bm25] Using NLTK stopwords + stemming\n",
      "\n",
      "⏱️ Tokenizing 28148 passages for BM25 ...\n",
      "✅ Tokenization complete in 14.36s\n",
      "\n",
      "⏱️ Building BM25 index ...\n",
      "✅ BM25 ready in 0.31s\n"
     ]
    }
   ],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "ACTIVE_PASSAGES = chunk_passages if USE_CHUNKING else passages\n",
    "\n",
    "# Tokenizer: NLTK stopwords + stemming → fallback regex\n",
    "USE_NLTK = True\n",
    "try:\n",
    "    import nltk\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk.stem import PorterStemmer\n",
    "    try: _ = stopwords.words(\"english\")\n",
    "    except LookupError:\n",
    "        print(\"[nltk] downloading stopwords...\"); nltk.download(\"stopwords\")\n",
    "    STOP = set(stopwords.words(\"english\")); STEM = PorterStemmer()\n",
    "    TOKEN_ALPHA = re.compile(r\"[A-Za-z]+\")\n",
    "    def _tok(text: str):\n",
    "        toks = TOKEN_ALPHA.findall(text.lower())\n",
    "        toks = [t for t in toks if t not in STOP]\n",
    "        toks = [STEM.stem(t) for t in toks]\n",
    "        return toks\n",
    "    print(\"[bm25] Using NLTK stopwords + stemming\")\n",
    "except Exception as e:\n",
    "    USE_NLTK = False\n",
    "    TOKEN_ALNUM = re.compile(r\"[A-Za-z0-9]+\")\n",
    "    def _tok(text: str): return TOKEN_ALNUM.findall(str(text).lower())\n",
    "    print(f\"[bm25] Fallback regex tokenizer ({e})\")\n",
    "\n",
    "t0 = tic(f\"Tokenizing {len(ACTIVE_PASSAGES)} passages for BM25\")\n",
    "tokenized = [_tok(p) for p in ACTIVE_PASSAGES]\n",
    "toc(t0, \"Tokenization complete\")\n",
    "\n",
    "t1 = tic(\"Building BM25 index\")\n",
    "bm25 = BM25Okapi(tokenized)\n",
    "toc(t1, \"BM25 ready\")\n",
    "\n",
    "def bm25_topk(query: str, k=10):\n",
    "    qtok = _tok(query)\n",
    "    scores = bm25.get_scores(qtok)\n",
    "    order = np.argsort(-scores)[:k]\n",
    "    return order.tolist(), scores[order].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9702227b-158c-4c55-9e54-eaa0b5362ea8",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "c9ed0164319e4b569669d6c6c84a8b58"
     ]
    },
    "id": "9702227b-158c-4c55-9e54-eaa0b5362ea8",
    "outputId": "84b1a696-a8f4-40f4-bd31-b851b85fb88a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading biomedical encoder from: /Users/harshasekar/Documents/UIUC/IS-567 Text Mining/Project/Code_V1/Models/S-PubMedBert-MS-MARCO\n",
      "✅ Encoder loaded\n",
      "\n",
      "⏱️ Encoding 28148 passages (normalize=True) ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9ed0164319e4b569669d6c6c84a8b58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/440 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Encoding complete in 3946.75s\n",
      "\n",
      "⏱️ Building cosine ANN (sklearn brute) ...\n",
      "✅ ANN ready in 0.02s\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import pathlib\n",
    "\n",
    "def load_pubmed_encoder(path=LOCAL_PUBMED):\n",
    "    p = pathlib.Path(path)\n",
    "    cand = list(p.glob(\"**/*.safetensors\")) + list(p.glob(\"**/pytorch_model.bin\"))\n",
    "    if not cand: raise RuntimeError(\"No weight files found. Did you run `git lfs pull` or download the repo ZIP?\")\n",
    "    small = [f for f in cand if f.stat().st_size < 10_000]\n",
    "    if small: raise RuntimeError(\"Found tiny Git-LFS pointer files; run `git lfs pull` in the model folder.\")\n",
    "    print(f\"Loading biomedical encoder from: {path}\")\n",
    "    enc = SentenceTransformer(path, device=\"cpu\")\n",
    "    print(\"✅ Encoder loaded\"); return enc\n",
    "\n",
    "encoder = load_pubmed_encoder(LOCAL_PUBMED)\n",
    "\n",
    "t0 = tic(f\"Encoding {len(ACTIVE_PASSAGES)} passages (normalize=True)\")\n",
    "embs = encoder.encode(\n",
    "    ACTIVE_PASSAGES,\n",
    "    normalize_embeddings=True,\n",
    "    convert_to_numpy=True,\n",
    "    show_progress_bar=True,\n",
    "    batch_size=64\n",
    ").astype(np.float32)\n",
    "toc(t0, \"Encoding complete\")\n",
    "\n",
    "t1 = tic(\"Building cosine ANN (sklearn brute)\")\n",
    "ann = NearestNeighbors(metric=\"cosine\", algorithm=\"brute\").fit(embs)\n",
    "toc(t1, \"ANN ready\")\n",
    "\n",
    "def dense_topk(query: str, k=10):\n",
    "    qv = encoder.encode([query], normalize_embeddings=True, convert_to_numpy=True, show_progress_bar=False)\n",
    "    dists, inds = ann.kneighbors(qv, n_neighbors=min(k, len(ACTIVE_PASSAGES)), return_distance=True)\n",
    "    sims = (1.0 - dists[0]); order = np.argsort(-sims)\n",
    "    return inds[0][order].tolist(), sims[order].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a33b6e-78a3-4e3d-8cb2-7806196a740e",
   "metadata": {
    "id": "87a33b6e-78a3-4e3d-8cb2-7806196a740e",
    "outputId": "98b4dde5-9bd0-4dc2-bb41-a9f6edbee41d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid (z-score) → top1: Key Points - Adult acute lymphoblastic leukemia (ALL) is a type of cancer in which the bone marrow makes too m …\n",
      "Hybrid (RRF) → top1: Key Points - Adult acute lymphoblastic leukemia (ALL) is a type of cancer in which the bone marrow makes too m …\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "def hybrid_topk(query, k=10, poolN=POOL_N, dedup_by_answer=USE_CHUNKING):\n",
    "    bi, bs = bm25_topk(query, k=poolN)\n",
    "    di, ds = dense_topk(query, k=poolN)\n",
    "\n",
    "    merged = {}\n",
    "    for i,s in zip(bi,bs): merged.setdefault(i, {})[\"bm25\"]  = float(s)\n",
    "    for i,s in zip(di,ds): merged.setdefault(i, {})[\"dense\"] = float(s)\n",
    "\n",
    "    idxs = list(merged.keys())\n",
    "    bm = np.array([merged[i].get(\"bm25\",0.0)  for i in idxs], dtype=float)\n",
    "    de = np.array([merged[i].get(\"dense\",0.0) for i in idxs], dtype=float)\n",
    "    hb = zscore(bm) if (len(bm)>1 and bm.std()>0) else bm\n",
    "    hd = zscore(de) if (len(de)>1 and de.std()>0) else de\n",
    "    hy = hb + hd\n",
    "    order = np.argsort(-hy)\n",
    "\n",
    "    if not dedup_by_answer:\n",
    "        top = order[:k]\n",
    "        return [idxs[o] for o in top], [float(hy[o]) for o in top]\n",
    "\n",
    "    # de-dup per original answer when chunking\n",
    "    if USE_CHUNKING and chunk2orig_idx is not None:\n",
    "        seen, out_idx, out_sc = set(), [], []\n",
    "        for o in order:\n",
    "            ch_i = idxs[o]\n",
    "            ans_i = chunk2orig_idx[ch_i]\n",
    "            if ans_i in seen: continue\n",
    "            seen.add(ans_i); out_idx.append(ch_i); out_sc.append(float(hy[o]))\n",
    "            if len(out_idx) == k: break\n",
    "        return out_idx, out_sc\n",
    "    else:\n",
    "        top = order[:k]\n",
    "        return [idxs[o] for o in top], [float(hy[o]) for o in top]\n",
    "\n",
    "# === RRF fusion (rank-based, robust) ===\n",
    "def rrf_topk(query, k=10, poolN=POOL_N, k_rrf=60, dedup_by_answer=USE_CHUNKING):\n",
    "    # get top pool from each retriever (indices into ACTIVE_PASSAGES)\n",
    "    bi, _ = bm25_topk(query, k=poolN)\n",
    "    di, _ = dense_topk(query, k=poolN)\n",
    "\n",
    "    # build rank maps (1-based ranks)\n",
    "    bm_rank = {idx: r for r, idx in enumerate(bi, start=1)}\n",
    "    de_rank = {idx: r for r, idx in enumerate(di, start=1)}\n",
    "\n",
    "    # accumulate RRF scores\n",
    "    scores = {}\n",
    "    for idx, r in bm_rank.items():\n",
    "        scores[idx] = scores.get(idx, 0.0) + 1.0 / (k_rrf + r)\n",
    "    for idx, r in de_rank.items():\n",
    "        scores[idx] = scores.get(idx, 0.0) + 1.0 / (k_rrf + r)\n",
    "\n",
    "    # sort by fused score\n",
    "    idxs = list(scores.keys())\n",
    "    vals = [scores[i] for i in idxs]\n",
    "    order = np.argsort(-np.array(vals))\n",
    "\n",
    "    if not dedup_by_answer:\n",
    "        top = order[:k]\n",
    "        return [idxs[o] for o in top], [float(vals[o]) for o in top]\n",
    "\n",
    "    # de-dup best per original answer when chunking\n",
    "    if USE_CHUNKING and chunk2orig_idx is not None:\n",
    "        seen, out_idx, out_sc = set(), [], []\n",
    "        for o in order:\n",
    "            i = idxs[o]\n",
    "            ans_i = chunk2orig_idx[i]\n",
    "            if ans_i in seen:\n",
    "                continue\n",
    "            seen.add(ans_i)\n",
    "            out_idx.append(i); out_sc.append(float(vals[o]))\n",
    "            if len(out_idx) == k: break\n",
    "        return out_idx, out_sc\n",
    "    else:\n",
    "        top = order[:k]\n",
    "        return [idxs[o] for o in top], [float(vals[o]) for o in top]\n",
    "\n",
    "# quick smoke test vs z-score fusion\n",
    "q_demo = \"What is adult acute lymphoblastic leukemia?\"\n",
    "for name, fn in [(\"Hybrid (z-score)\", hybrid_topk),\n",
    "                 (\"Hybrid (RRF)\",     rrf_topk)]:\n",
    "    idxs,_ = fn(q_demo, k=5)\n",
    "    i0 = idxs[0]\n",
    "    src = passages[chunk2orig_idx[i0]] if USE_CHUNKING else passages[i0]\n",
    "    print(f\"{name} → top1:\", preview(src, 110), \"…\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81455fb-dab2-414e-a1af-1ebc02076683",
   "metadata": {
    "id": "f81455fb-dab2-414e-a1af-1ebc02076683",
    "outputId": "c8d78383-7448-4ce8-ea94-92b1a38df586"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== BM25 @K=10 ===\n",
      "  progress: 25/1818\n",
      "  progress: 50/1818\n",
      "  progress: 75/1818\n",
      "  progress: 100/1818\n",
      "  progress: 125/1818\n",
      "  progress: 150/1818\n",
      "  progress: 175/1818\n",
      "  progress: 200/1818\n",
      "  progress: 225/1818\n",
      "  progress: 250/1818\n",
      "  progress: 275/1818\n",
      "  progress: 300/1818\n",
      "  progress: 325/1818\n",
      "  progress: 350/1818\n",
      "  progress: 375/1818\n",
      "  progress: 400/1818\n",
      "  progress: 425/1818\n",
      "  progress: 450/1818\n",
      "  progress: 475/1818\n",
      "  progress: 500/1818\n",
      "  progress: 525/1818\n",
      "  progress: 550/1818\n",
      "  progress: 575/1818\n",
      "  progress: 600/1818\n",
      "  progress: 625/1818\n",
      "  progress: 650/1818\n",
      "  progress: 675/1818\n",
      "  progress: 700/1818\n",
      "  progress: 725/1818\n",
      "  progress: 750/1818\n",
      "  progress: 775/1818\n",
      "  progress: 800/1818\n",
      "  progress: 825/1818\n",
      "  progress: 850/1818\n",
      "  progress: 875/1818\n",
      "  progress: 900/1818\n",
      "  progress: 925/1818\n",
      "  progress: 950/1818\n",
      "  progress: 975/1818\n",
      "  progress: 1000/1818\n",
      "  progress: 1025/1818\n",
      "  progress: 1050/1818\n",
      "  progress: 1075/1818\n",
      "  progress: 1100/1818\n",
      "  progress: 1125/1818\n",
      "  progress: 1150/1818\n",
      "  progress: 1175/1818\n",
      "  progress: 1200/1818\n",
      "  progress: 1225/1818\n",
      "  progress: 1250/1818\n",
      "  progress: 1275/1818\n",
      "  progress: 1300/1818\n",
      "  progress: 1325/1818\n",
      "  progress: 1350/1818\n",
      "  progress: 1375/1818\n",
      "  progress: 1400/1818\n",
      "  progress: 1425/1818\n",
      "  progress: 1450/1818\n",
      "  progress: 1475/1818\n",
      "  progress: 1500/1818\n",
      "  progress: 1525/1818\n",
      "  progress: 1550/1818\n",
      "  progress: 1575/1818\n",
      "  progress: 1600/1818\n",
      "  progress: 1625/1818\n",
      "  progress: 1650/1818\n",
      "  progress: 1675/1818\n",
      "  progress: 1700/1818\n",
      "  progress: 1725/1818\n",
      "  progress: 1750/1818\n",
      "  progress: 1775/1818\n",
      "  progress: 1800/1818\n",
      "  progress: 1818/1818\n",
      "→ Recall@10: 0.822 | MRR@10: 0.494\n",
      "\n",
      "=== Dense (PubMedBERT) @K=10 ===\n",
      "  progress: 25/1818\n",
      "  progress: 50/1818\n",
      "  progress: 75/1818\n",
      "  progress: 100/1818\n",
      "  progress: 125/1818\n",
      "  progress: 150/1818\n",
      "  progress: 175/1818\n",
      "  progress: 200/1818\n",
      "  progress: 225/1818\n",
      "  progress: 250/1818\n",
      "  progress: 275/1818\n",
      "  progress: 300/1818\n",
      "  progress: 325/1818\n",
      "  progress: 350/1818\n",
      "  progress: 375/1818\n",
      "  progress: 400/1818\n",
      "  progress: 425/1818\n",
      "  progress: 450/1818\n",
      "  progress: 475/1818\n",
      "  progress: 500/1818\n",
      "  progress: 525/1818\n",
      "  progress: 550/1818\n",
      "  progress: 575/1818\n",
      "  progress: 600/1818\n",
      "  progress: 625/1818\n",
      "  progress: 650/1818\n",
      "  progress: 675/1818\n",
      "  progress: 700/1818\n",
      "  progress: 725/1818\n",
      "  progress: 750/1818\n",
      "  progress: 775/1818\n",
      "  progress: 800/1818\n",
      "  progress: 825/1818\n",
      "  progress: 850/1818\n",
      "  progress: 875/1818\n",
      "  progress: 900/1818\n",
      "  progress: 925/1818\n",
      "  progress: 950/1818\n",
      "  progress: 975/1818\n",
      "  progress: 1000/1818\n",
      "  progress: 1025/1818\n",
      "  progress: 1050/1818\n",
      "  progress: 1075/1818\n",
      "  progress: 1100/1818\n",
      "  progress: 1125/1818\n",
      "  progress: 1150/1818\n",
      "  progress: 1175/1818\n",
      "  progress: 1200/1818\n",
      "  progress: 1225/1818\n",
      "  progress: 1250/1818\n",
      "  progress: 1275/1818\n",
      "  progress: 1300/1818\n",
      "  progress: 1325/1818\n",
      "  progress: 1350/1818\n",
      "  progress: 1375/1818\n",
      "  progress: 1400/1818\n",
      "  progress: 1425/1818\n",
      "  progress: 1450/1818\n",
      "  progress: 1475/1818\n",
      "  progress: 1500/1818\n",
      "  progress: 1525/1818\n",
      "  progress: 1550/1818\n",
      "  progress: 1575/1818\n",
      "  progress: 1600/1818\n",
      "  progress: 1625/1818\n",
      "  progress: 1650/1818\n",
      "  progress: 1675/1818\n",
      "  progress: 1700/1818\n",
      "  progress: 1725/1818\n",
      "  progress: 1750/1818\n",
      "  progress: 1775/1818\n",
      "  progress: 1800/1818\n",
      "  progress: 1818/1818\n",
      "→ Recall@10: 0.898 | MRR@10: 0.699\n",
      "\n",
      "=== Hybrid (z-score) @K=10 ===\n",
      "  progress: 25/1818\n",
      "  progress: 50/1818\n",
      "  progress: 75/1818\n",
      "  progress: 100/1818\n",
      "  progress: 125/1818\n",
      "  progress: 150/1818\n",
      "  progress: 175/1818\n",
      "  progress: 200/1818\n",
      "  progress: 225/1818\n",
      "  progress: 250/1818\n",
      "  progress: 275/1818\n",
      "  progress: 300/1818\n",
      "  progress: 325/1818\n",
      "  progress: 350/1818\n",
      "  progress: 375/1818\n",
      "  progress: 400/1818\n",
      "  progress: 425/1818\n",
      "  progress: 450/1818\n",
      "  progress: 475/1818\n",
      "  progress: 500/1818\n",
      "  progress: 525/1818\n",
      "  progress: 550/1818\n",
      "  progress: 575/1818\n",
      "  progress: 600/1818\n",
      "  progress: 625/1818\n",
      "  progress: 650/1818\n",
      "  progress: 675/1818\n",
      "  progress: 700/1818\n",
      "  progress: 725/1818\n",
      "  progress: 750/1818\n",
      "  progress: 775/1818\n",
      "  progress: 800/1818\n",
      "  progress: 825/1818\n",
      "  progress: 850/1818\n",
      "  progress: 875/1818\n",
      "  progress: 900/1818\n",
      "  progress: 925/1818\n",
      "  progress: 950/1818\n",
      "  progress: 975/1818\n",
      "  progress: 1000/1818\n",
      "  progress: 1025/1818\n",
      "  progress: 1050/1818\n",
      "  progress: 1075/1818\n",
      "  progress: 1100/1818\n",
      "  progress: 1125/1818\n",
      "  progress: 1150/1818\n",
      "  progress: 1175/1818\n",
      "  progress: 1200/1818\n",
      "  progress: 1225/1818\n",
      "  progress: 1250/1818\n",
      "  progress: 1275/1818\n",
      "  progress: 1300/1818\n",
      "  progress: 1325/1818\n",
      "  progress: 1350/1818\n",
      "  progress: 1375/1818\n",
      "  progress: 1400/1818\n",
      "  progress: 1425/1818\n",
      "  progress: 1450/1818\n",
      "  progress: 1475/1818\n",
      "  progress: 1500/1818\n",
      "  progress: 1525/1818\n",
      "  progress: 1550/1818\n",
      "  progress: 1575/1818\n",
      "  progress: 1600/1818\n",
      "  progress: 1625/1818\n",
      "  progress: 1650/1818\n",
      "  progress: 1675/1818\n",
      "  progress: 1700/1818\n",
      "  progress: 1725/1818\n",
      "  progress: 1750/1818\n",
      "  progress: 1775/1818\n",
      "  progress: 1800/1818\n",
      "  progress: 1818/1818\n",
      "→ Recall@10: 0.879 | MRR@10: 0.541\n",
      "\n",
      "=== Hybrid (RRF) @K=10 ===\n",
      "  progress: 25/1818\n",
      "  progress: 50/1818\n",
      "  progress: 75/1818\n",
      "  progress: 100/1818\n",
      "  progress: 125/1818\n",
      "  progress: 150/1818\n",
      "  progress: 175/1818\n",
      "  progress: 200/1818\n",
      "  progress: 225/1818\n",
      "  progress: 250/1818\n",
      "  progress: 275/1818\n",
      "  progress: 300/1818\n",
      "  progress: 325/1818\n",
      "  progress: 350/1818\n",
      "  progress: 375/1818\n",
      "  progress: 400/1818\n",
      "  progress: 425/1818\n",
      "  progress: 450/1818\n",
      "  progress: 475/1818\n",
      "  progress: 500/1818\n",
      "  progress: 525/1818\n",
      "  progress: 550/1818\n",
      "  progress: 575/1818\n",
      "  progress: 600/1818\n",
      "  progress: 625/1818\n",
      "  progress: 650/1818\n",
      "  progress: 675/1818\n",
      "  progress: 700/1818\n",
      "  progress: 725/1818\n",
      "  progress: 750/1818\n",
      "  progress: 775/1818\n",
      "  progress: 800/1818\n",
      "  progress: 825/1818\n",
      "  progress: 850/1818\n",
      "  progress: 875/1818\n",
      "  progress: 900/1818\n",
      "  progress: 925/1818\n",
      "  progress: 950/1818\n",
      "  progress: 975/1818\n",
      "  progress: 1000/1818\n",
      "  progress: 1025/1818\n",
      "  progress: 1050/1818\n",
      "  progress: 1075/1818\n",
      "  progress: 1100/1818\n",
      "  progress: 1125/1818\n",
      "  progress: 1150/1818\n",
      "  progress: 1175/1818\n",
      "  progress: 1200/1818\n",
      "  progress: 1225/1818\n",
      "  progress: 1250/1818\n",
      "  progress: 1275/1818\n",
      "  progress: 1300/1818\n",
      "  progress: 1325/1818\n",
      "  progress: 1350/1818\n",
      "  progress: 1375/1818\n",
      "  progress: 1400/1818\n",
      "  progress: 1425/1818\n",
      "  progress: 1450/1818\n",
      "  progress: 1475/1818\n",
      "  progress: 1500/1818\n",
      "  progress: 1525/1818\n",
      "  progress: 1550/1818\n",
      "  progress: 1575/1818\n",
      "  progress: 1600/1818\n",
      "  progress: 1625/1818\n",
      "  progress: 1650/1818\n",
      "  progress: 1675/1818\n",
      "  progress: 1700/1818\n",
      "  progress: 1725/1818\n",
      "  progress: 1750/1818\n",
      "  progress: 1775/1818\n",
      "  progress: 1800/1818\n",
      "  progress: 1818/1818\n",
      "→ Recall@10: 0.897 | MRR@10: 0.634\n",
      "\n",
      "=== Summary @K=10 ===\n",
      "BM25           → Recall: 0.822 | MRR: 0.494\n",
      "Dense          → Recall: 0.898 | MRR: 0.699\n",
      "Hybrid z-score → Recall: 0.879 | MRR: 0.541\n",
      "Hybrid RRF     → Recall: 0.897 | MRR: 0.634\n"
     ]
    }
   ],
   "source": [
    "# ===== Step 5 — Evaluation: Recall@K and MRR (BM25, Dense, Hybrid z-score, Hybrid RRF) =====\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "EVAL_K = EVAL_K if 'EVAL_K' in globals() else 10  # keep your earlier setting if defined\n",
    "\n",
    "# Hit function: ROUGE-L overlap between retrieved text and gold answer\n",
    "scorer = rouge_scorer.RougeScorer([\"rougeL\"], use_stemmer=True)\n",
    "def _is_hit(pred_text: str, gold_answer: str, thresh: float = 0.20) -> bool:\n",
    "    return scorer.score(gold_answer, pred_text)[\"rougeL\"].fmeasure >= thresh\n",
    "\n",
    "# Where to read texts from (chunk text if chunking, else full answer text)\n",
    "def _text_by_idx(i: int) -> str:\n",
    "    return ACTIVE_PASSAGES[i]\n",
    "\n",
    "# Build eval lists from your test split\n",
    "q_list = test_df[\"question\"].astype(str).tolist()\n",
    "a_list = test_df[\"answer\"].astype(str).tolist()\n",
    "\n",
    "def eval_retriever(name: str, retr_fn, K: int = EVAL_K, show_every: int = 25):\n",
    "    \"\"\"\n",
    "    retr_fn must be a callable: retr_fn(question_str, k) -> (indices_list, scores_list)\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== {name} @K={K} ===\")\n",
    "    hits = 0\n",
    "    rr_sum = 0.0\n",
    "\n",
    "    for n, (q, gold) in enumerate(zip(q_list, a_list), start=1):\n",
    "        idxs, _ = retr_fn(q, K)\n",
    "        rank = None\n",
    "        for r, idx in enumerate(idxs, start=1):\n",
    "            if _is_hit(_text_by_idx(idx), gold):\n",
    "                rank = r\n",
    "                break\n",
    "        if rank is not None:\n",
    "            hits += 1\n",
    "            rr_sum += 1.0 / rank\n",
    "\n",
    "        if (n % show_every == 0) or (n == len(q_list)):\n",
    "            print(f\"  progress: {n}/{len(q_list)}\")\n",
    "\n",
    "    recall = hits / len(q_list) if q_list else 0.0\n",
    "    mrr    = rr_sum / len(q_list) if q_list else 0.0\n",
    "    print(f\"→ Recall@{K}: {recall:.3f} | MRR@{K}: {mrr:.3f}\")\n",
    "    return recall, mrr\n",
    "\n",
    "# Wrappers so eval_retriever can call each method uniformly\n",
    "def _bm25_wrap(q, k):   return bm25_topk(q, k)\n",
    "def _dense_wrap(q, k):  return dense_topk(q, k)\n",
    "def _zscore_wrap(q, k): return hybrid_topk(q, k)          # z-score fusion\n",
    "def _rrf_wrap(q, k):    return rrf_topk(q, k)             # reciprocal-rank fusion\n",
    "\n",
    "# Run all four and collect results\n",
    "Rbm, Mbm = eval_retriever(\"BM25\",              _bm25_wrap,   K=EVAL_K)\n",
    "Rde, Mde = eval_retriever(\"Dense (PubMedBERT)\", _dense_wrap,  K=EVAL_K)\n",
    "Rhy, Mhy = eval_retriever(\"Hybrid (z-score)\",   _zscore_wrap, K=EVAL_K)\n",
    "Rrf, Mrf = eval_retriever(\"Hybrid (RRF)\",       _rrf_wrap,    K=EVAL_K)\n",
    "\n",
    "# Optional: quick summary print\n",
    "print(\"\\n=== Summary @K={} ===\".format(EVAL_K))\n",
    "print(\"BM25           → Recall: {:.3f} | MRR: {:.3f}\".format(Rbm, Mbm))\n",
    "print(\"Dense          → Recall: {:.3f} | MRR: {:.3f}\".format(Rde, Mde))\n",
    "print(\"Hybrid z-score → Recall: {:.3f} | MRR: {:.3f}\".format(Rhy, Mhy))\n",
    "print(\"Hybrid RRF     → Recall: {:.3f} | MRR: {:.3f}\".format(Rrf, Mrf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a832b16e-c286-42f5-ba3f-31dc6f75800e",
   "metadata": {
    "id": "a832b16e-c286-42f5-ba3f-31dc6f75800e"
   },
   "outputs": [],
   "source": [
    "# ===== G1 — Generator config =====\n",
    "FUSION = \"rrf\"        # options: \"bm25\", \"dense\", \"z\" (z-score), \"rrf\"\n",
    "GEN_TOPK = 3          # how many retrieved passages to include in context\n",
    "N_SAMPLES = 8         # how many test questions to show (set None to use ALL)\n",
    "MAX_INPUT_TOKENS = 512\n",
    "MAX_NEW_TOKENS   = 160\n",
    "GEN_STYLE = \"concise\" # \"concise\" | \"patient_friendly\" | \"bullet_points\"\n",
    "SEED = 13\n",
    "\n",
    "import random, numpy as np\n",
    "random.seed(SEED); np.random.seed(SEED)\n",
    "\n",
    "# Select a retriever by name (must match FUSION)\n",
    "def _get_retr_fn():\n",
    "    if FUSION == \"bm25\":\n",
    "        return lambda q, k: bm25_topk(q, k)\n",
    "    if FUSION == \"dense\":\n",
    "        return lambda q, k: dense_topk(q, k)\n",
    "    if FUSION == \"z\":\n",
    "        return lambda q, k: hybrid_topk(q, k)      # z-score fusion\n",
    "    if FUSION == \"rrf\":\n",
    "        return lambda q, k: rrf_topk(q, k)         # reciprocal-rank fusion\n",
    "    raise ValueError(\"FUSION must be one of: bm25 | dense | z | rrf\")\n",
    "\n",
    "RETRIEVE = _get_retr_fn()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c3801c-0e86-4c87-8156-f5edb4382076",
   "metadata": {
    "id": "e0c3801c-0e86-4c87-8156-f5edb4382076",
    "outputId": "af00eb54-b84b-486b-c7a9-e502ca1b72dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading generator: t5-small\n",
      "✅ Generator ready\n"
     ]
    }
   ],
   "source": [
    "# ===== G2 — Load generator (T5-small by default) =====\n",
    "from transformers import T5ForConditionalGeneration, T5TokenizerFast\n",
    "\n",
    "GEN_MODEL_ID = \"t5-small\"   # swap to \"google/flan-t5-base\" for stronger gen (slower)\n",
    "# If you downloaded a local generator, set: GEN_MODEL_ID = \"/path/to/local/t5-small\"\n",
    "\n",
    "print(f\"Loading generator: {GEN_MODEL_ID}\")\n",
    "gen_tok = T5TokenizerFast.from_pretrained(GEN_MODEL_ID)\n",
    "gen_mdl = T5ForConditionalGeneration.from_pretrained(GEN_MODEL_ID)\n",
    "print(\"✅ Generator ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019c07ab-af2b-47c1-8a37-d8d6188a2b84",
   "metadata": {
    "id": "019c07ab-af2b-47c1-8a37-d8d6188a2b84"
   },
   "outputs": [],
   "source": [
    "# ===== G3 — Guarded prompt + retrieval → generation helpers =====\n",
    "from rouge_score import rouge_scorer\n",
    "scorer = rouge_scorer.RougeScorer([\"rougeL\"], use_stemmer=True)\n",
    "\n",
    "def _format_context(ctx_texts):\n",
    "    # Number each context so we can cite [C1], [C2], ...\n",
    "    lines = []\n",
    "    for i, t in enumerate(ctx_texts, start=1):\n",
    "        clean = str(t).replace(\"\\n\", \" \").strip()\n",
    "        lines.append(f\"[C{i}] {clean}\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def _style_instructions(style: str) -> str:\n",
    "    if style == \"patient_friendly\":\n",
    "        return (\"- Write in plain, patient-friendly language.\\n\"\n",
    "                \"- Define medical terms briefly when first used.\\n\"\n",
    "                \"- Keep the answer to 3–5 short sentences.\\n\")\n",
    "    if style == \"bullet_points\":\n",
    "        return (\"- Answer using 3–6 short bullet points.\\n\"\n",
    "                \"- Each bullet should be one sentence.\\n\")\n",
    "    return (\"- Answer in 2–4 concise sentences.\\n\"\n",
    "            \"- Be direct and specific.\\n\")\n",
    "\n",
    "def build_prompt_t5_detailed(question: str, ctx_texts, style: str):\n",
    "    ctx_block = _format_context(ctx_texts)\n",
    "    style_block = _style_instructions(style)\n",
    "    return (\n",
    "f\"You are a biomedical QA assistant. Use ONLY the information in CONTEXT to answer the QUESTION.\\n\"\n",
    "f\"If the answer is not clearly supported by CONTEXT, reply exactly: NOT ENOUGH INFO\\n\\n\"\n",
    "f\"GUIDELINES:\\n\"\n",
    "f\"- Ground every claim in the numbered CONTEXT items below.\\n\"\n",
    "f\"- Add inline citations to the specific items you used, like [C1] or [C1][C3].\\n\"\n",
    "f\"- Do NOT invent facts, do NOT speculate, do NOT use outside knowledge.\\n\"\n",
    "f\"- If multiple CONTEXT items disagree, prefer the more specific or definition-like statements and acknowledge uncertainty.\\n\"\n",
    "f\"{style_block}\"\n",
    "f\"- Keep abbreviations expanded on first use (e.g., \\\"acute lymphoblastic leukemia (ALL)\\\"), then you may use the abbreviation.\\n\"\n",
    "f\"- Do NOT include your reasoning steps. Only output the final answer text.\\n\\n\"\n",
    "f\"QUESTION:\\n{question}\\n\\n\"\n",
    "f\"CONTEXT:\\n{ctx_block}\\n\\n\"\n",
    "f\"ANSWER:\"\n",
    "    )\n",
    "\n",
    "def retrieve_context(question: str, topk: int = GEN_TOPK):\n",
    "    idxs, _ = RETRIEVE(question, k=topk)\n",
    "    ctx_texts = [ACTIVE_PASSAGES[i] for i in idxs]\n",
    "    return idxs, ctx_texts\n",
    "\n",
    "def generate_answer(question: str, topk=GEN_TOPK,\n",
    "                    max_input_tokens=MAX_INPUT_TOKENS,\n",
    "                    max_new_tokens=MAX_NEW_TOKENS,\n",
    "                    style: str = GEN_STYLE):\n",
    "    idxs, ctx_texts = retrieve_context(question, topk=topk)\n",
    "    prompt = build_prompt_t5_detailed(question, ctx_texts, style)\n",
    "    enc = gen_tok(prompt, return_tensors=\"pt\", truncation=True, max_length=max_input_tokens)\n",
    "    out = gen_mdl.generate(**enc, max_new_tokens=max_new_tokens, do_sample=False)\n",
    "    gen_text = gen_tok.decode(out[0], skip_special_tokens=True).strip()\n",
    "    return gen_text, idxs, ctx_texts, prompt\n",
    "\n",
    "def rougeL_f1(pred: str, gold: str) -> float:\n",
    "    return scorer.score(gold, pred)[\"rougeL\"].fmeasure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6818d312-12da-4a3b-b80f-b7895b2ea1fe",
   "metadata": {
    "id": "6818d312-12da-4a3b-b80f-b7895b2ea1fe",
    "outputId": "93628751-cc32-4281-e422-c474d838146b"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Q (#466):** How many people are affected by juvenile Batten disease ?\n",
       "\n",
       "**Generated (ROUGE-L=0.396):**  \n",
       "QUESTION: How many people are affected by juvenile batten disease? CONTEXT: [C1] in mid to late childhood most people with juvenile batten disease live into their twenties or thirties juvenile batten disease is one of a group of disorders known as neuronal ceroid lipofuscinoses ncls. ncls are more common in finland where approximately 1 in 12 500 individuals are affected [C3] most cases of juvenile batten\n",
       "\n",
       "**Gold:**  \n",
       "Juvenile Batten disease is the most common type of NCL, but its exact prevalence is unknown. Collectively, all forms of NCL affect an estimated 1 in 100,000 individuals worldwide. NCLs are more common in Finland, where approximately 1 in 12,500 individuals are affected.\n",
       "\n",
       "**Retrieved (top-3 snippets):**  \n",
       "in mid to late childhood most people with juvenile batten disease live into their twenties or thirties juvenile batten disease is one of a g… | juvenile batten disease is the most common type of ncl but its exact prevalence is unknown collectively all forms of ncl affect an estimated… | most cases of juvenile batten disease are caused by mutations in the cln3 gene this gene provides instructions for making a protein whose fu…"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Q (#1563):** Who is at risk for Nocardiosis? ?\n",
       "\n",
       "**Generated (ROUGE-L=0.144):**  \n",
       "QUESTION: Who is at risk for Nocardiosis?? CONTEXT: [C1] the bacteria that cause nocardiosis are commonly found in soil and water you could become sick with nocardiosis if you inhale breathe in the bacteria bacteria gets into an open wound or cut in rare cases infection can occur during surgical procedures.\n",
       "\n",
       "**Gold:**  \n",
       "People with very weak immune (body defense) systems are at risk for getting nocardiosis. Several diseases and circumstances can cause the immune system to be weak. These include: - Diabetes - Cancer - HIV/AIDS - Pulmonary alveolar proteinosis (an illness that causes the air sacs of the lungs to become plugged) - Connective tissue disorder (a disease that affects the tissue that connects and supports different parts of the body) - Alcoholism - Having a bone marrow or solid organ transplant - Taking high doses of drugs called corticosteroids In the United States, it has been estimated that 500-1,000 new cases of nocardiosis infection occur every year. Approximately 60% of nocardiosis cases are associated with pre-existing immune compromise. In addition, men have a greater risk of getting the infection than women; for every female who gets sick with nocardiosis, there are about 3 males who get the disease.\n",
       "\n",
       "**Retrieved (top-3 snippets):**  \n",
       "the bacteria that cause nocardiosis are commonly found in soil and water you could become sick with nocardiosis if you inhale breathe in the… | people with very weak immune body defense systems are at risk for getting nocardiosis several diseases and circumstances can cause the immun… | if you think you might be sick with nocardiosis talk to your doctor he or she can help find out if you have the disease by performing tests …"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Q (#784):** What is (are) Hereditary sensory neuropathy type 1 ?\n",
       "\n",
       "**Generated (ROUGE-L=0.139):**  \n",
       "QUESTION: What is (are) hereditary sensory neuropathy type 1? CONTEXT: [C1] hereditary neuropathies are a group of inherited disorders affecting the peripheral nervous system. hereditary motor and sensory neuropathy hereditary motor neuropathy and hereditary sensory and autonomic neuropathy. charcot marie tooth disease one of the most common type is charcot marie tooth disease one of the hereditary neuropathies symptoms vary according the\n",
       "\n",
       "**Gold:**  \n",
       "Hereditary sensory neuropathy type 1 (HSN1) is a neurological condition characterized by nerve abnormalities in the legs and feet. Many people with this condition have tingling, weakness, and a reduced ability to feel pain and sense hot and cold. Some affected people do not lose sensation, but instead feel shooting pains in their legs and feet. As HSN1 progresses, sensory problems can affect the hands, arms, shoulders, and abdomen. In rare cases, people with this condition develop sensorineural hearing loss. Symptoms of HSN1 typically begin during a person's teens or twenties and worsen over time. HSN1 is caused by mutations in any of several genes, depending on the form of HSN1 (HSN1A is caused by mutations in the SPTLC1 gene; HSN1B is linked to a gene located in chromosome 3; HSN1C is caused by mutations in the SPTLC2 gene; HSN1D is caused by mutations in the ATL1 gene and HSN1E is caused by mutations in DNMT1 gene. All forms of HSN1 are inherited in an autosomal dominant manner. If symptoms are treated properly, the condition does not appear to affect life expectancy.\n",
       "\n",
       "**Retrieved (top-3 snippets):**  \n",
       "hereditary neuropathies are a group of inherited disorders affecting the peripheral nervous system the hereditary neuropathies are divided i… | hereditary sensory neuropathy type ia is a condition characterized by nerve abnormalities in the legs and feet peripheral neuropathy many pe… | hereditary sensory neuropathy type ia is a rare condition its prevalence is estimated to be 1 to 2 per 100 000 individuals…"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Q (#715):** What is (are) Blount disease ?\n",
       "\n",
       "**Generated (ROUGE-L=0.114):**  \n",
       "if the information is available you can use the medlineplus medical dictionary to look up the definitions for these medical terms signs and symptoms. - Answer in 2–4 concise sentences. - Be direct and specific. - Be direct and specific. - If multiple CONTEXT items disagree, prefer the more specific or definition-like statements and acknowledge uncertainty. - Use the final answer text. - Answer in 2–4 concise sentences. - Do NOT invent facts, do NOT speculate, do NOT use\n",
       "\n",
       "**Gold:**  \n",
       "Blount disease is characterized by progressive bowing of the legs in infancy, early childhood, or adolescence. While it is not uncommon for young children to have bowed legs, typically the bowing improves with age. Blount disease is a condition that results from abnormal growth in the upper part of the shin bone (tibia) and requires treatment for improvement to occur. Treatment may involve bracing and/or surgery. Other causes for Blount disease in young children includes metabolic disease and rickets. Blount disease in teens typically occurs in youth who are overweight. In teens surgery is often required to correct the problem.\n",
       "\n",
       "**Retrieved (top-3 snippets):**  \n",
       "blount disease is characterized by progressive bowing of the legs in infancy early childhood or adolescence while it is not uncommon for you… | what are the signs and symptoms of blount disease the human phenotype ontology provides the following list of signs and symptoms for blount … | these resources address the diagnosis or management of parkinson disease gene review gene review parkinson disease overview genetic testing …"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Q (#976):** Is 48,XXYY syndrome inherited ?\n",
       "\n",
       "**Generated (ROUGE-L=0.110):**  \n",
       "? QUESTION: [C2] 48 xxyy syndrome is a chromosomal condition that causes medical and behavioral problems in males 48 xxyy syndrome. 48 xxyy syndrome disrupts male sexual development adolescent and adult males with this condition typically have small testes that do not produce enough testosterone. 48 xxyy syndrome can affect other parts of the body as well males with 48 xxyy syndrome are often taller than other male\n",
       "\n",
       "**Gold:**  \n",
       "Can 48,XXYY syndrome be inherited?\n",
       "\n",
       "**Retrieved (top-3 snippets):**  \n",
       "can 48 xxyy syndrome be inherited… | 48 xxyy syndrome is a chromosomal condition that causes medical and behavioral problems in males 48 xxyy disrupts male sexual development ad… | 48 xxyy syndrome is estimated to affect 1 in 18 000 to 50 000 males…"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Q (#1150):** What is the outlook for Cephalic Disorders ?\n",
       "\n",
       "**Generated (ROUGE-L=0.098):**  \n",
       "- Use ONLY the information in CONTEXT to answer the QUESTION. - Answer in 2–4 concise sentences. - Be direct and specific. - Be direct and specific. - Be direct and specific. - Be direct and specific. - Be direct and specific. - Be direct and specific. - Be direct and specific. - Be direct and specific. - If multiple CONTEXT items disagree, prefer the more specific or definition-like statements and acknowledge uncertainty. - Answer\n",
       "\n",
       "**Gold:**  \n",
       "The degree to which damage to the developing nervous system harms the mind and body varies enormously. Many disabilities are mild enough to allow those afflicted to eventually function independently in society. Others are not. Some infants, children, and adults die; others remain totally disabled; and an even larger population is partially disabled, functioning well below normal capacity.\n",
       "\n",
       "**Retrieved (top-3 snippets):**  \n",
       "cephalic disorders are congenital conditions that stem from damage to or abnormal development of the budding nervous system most cephalic di… | treatments for cephalic disorders depend upon the particular type of disorder for most cephalic disorders treatment is only symptomatic and … | the outlook for children with hydranencephaly is generally poor and many children with this disorder die before age 1 however in rare cases …"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Q (#1465):** Who is at risk for Diabetes? ?\n",
       "\n",
       "**Generated (ROUGE-L=0.089):**  \n",
       "the answer text. QUESTION: Who is at risk for Diabetes?? CONTEXT: [C1] risk learn more about the causes of type 1 diabetes type 2 diabetes type 2 diabetes type 2 diabetes the most common form is linked closely to overweight and obesity high blood pressure and abnormal cholesterol levels.\n",
       "\n",
       "**Gold:**  \n",
       "Here are the risk factors for type 2 diabetes. - being over 45 years of age - being overweight or obese - having a first-degree relative -- a parent, brother, or sister -- with diabetes - being African American, American Indian or Alaska Native, Asian American or Pacific Islander, or Hispanic American/Latino. (Watch the video to learn more about native Americans and diabetes risk. To enlarge the video, click the brackets in the lower right-hand corner. To reduce the video, press the Escape (Esc) button on your keyboard.) - having gestational diabetes, or giving birth to at least one baby weighing more than 9 pounds - having blood pressure of 140/90 or higher, or having been told that you have high blood pressure. - having abnormal cholesterol levels -- an HDL cholesterol level of 35 or lower, or a triglyceride level of 250 or higher - being inactive or exercising fewer than three times a week. - having polycystic ovary syndrome, also called PCOS (women only) - on previous testing, having prediabetes (an A1C level of 5.7 to 6.4 percent), impaired glucose tolerance (IGT) or impaired fasting glucose (IFG) - history of cardiovascular disease (disease affecting the heart and blood vessels). being over 45 years of age being overweight or obese having a first-degree relative -- a parent, brother, or sister -- with diabetes being African American, American Indian or Alaska Native, Asian American or Pacific Islander, or Hispanic American/Latino. (Watch the video to learn more about native Americans and diabetes risk. To enlarge the video, click the brackets in the lower right-hand corner. To reduce the video, press the Escape (Esc) button on your keyboard.) having gestational diabetes, or giving birth to at least one baby weighing more than 9 pounds having blood pressure of 140/90 or higher, or having been told that you have high blood pressure. having abnormal cholesterol levels -- an HDL cholesterol level of 35 or lower, or a triglyceride level of 250 or higher being inactive or exercising fewer than three times a week. having polycystic ovary syndrome, also called PCOS (women only) on previous testing, having prediabetes (an A1C level of 5.7 to 6.4 percent), impaired glucose tolerance (IGT) or impaired fasting glucose (IFG) history of cardiovascular disease (disease affecting the heart and blood vessels).\n",
       "\n",
       "**Retrieved (top-3 snippets):**  \n",
       "risk learn more about the causes of type 1 diabetes type 2 diabetes type 2 diabetes the most common form is linked closely to overweight and… | people who have type 1 or type 2 diabetes are at risk for diabetic heart disease dhd diabetes affects heart disease risk in three major ways… | prediabetes means your blood glucose levels are higher than normal but not high enough for a diagnosis of diabetes in 2012 about 86 million …"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Q (#650):** What are the symptoms of De Barsy syndrome ?\n",
       "\n",
       "**Generated (ROUGE-L=0.046):**  \n",
       "? QUESTION: [C1] what are the signs and symptoms of de barsy syndrome?????????????????????????????????????????????\n",
       "\n",
       "**Gold:**  \n",
       "What are the signs and symptoms of De Barsy syndrome? The Human Phenotype Ontology provides the following list of signs and symptoms for De Barsy syndrome. If the information is available, the table below includes how often the symptom is seen in people with this condition. You can use the MedlinePlus Medical Dictionary to look up the definitions for these medical terms. Signs and Symptoms Approximate number of patients (when available) Abnormality of the fontanelles or cranial sutures 90% Cataract 90% Cognitive impairment 90% Cutis laxa 90% Hyperextensible skin 90% Hyperreflexia 90% Joint hypermobility 90% Muscular hypotonia 90% Opacification of the corneal stroma 90% Prematurely aged appearance 90% Short stature 90% Wide nasal bridge 90% Abnormality of adipose tissue 50% Aplasia/Hypoplasia of the corpus callosum 50% Aplasia/Hypoplasia of the skin 50% Broad forehead 50% Macrotia 50% Abnormality of female external genitalia 7.5% Abnormality of skin pigmentation 7.5% Abnormality of the hip bone 7.5% Adducted thumb 7.5% Aplasia/Hypoplasia of the abdominal wall musculature 7.5% Blue sclerae 7.5% Chorea 7.5% Flexion contracture 7.5% Genu recurvatum 7.5% Joint dislocation 7.5% Pectus excavatum 7.5% Reduced bone mineral density 7.5% Scoliosis 7.5% Umbilical hernia 7.5% Cryptorchidism 5% Athetosis - Autosomal recessive inheritance - Brachycephaly - Congenital hip dislocation - Corneal arcus - Delayed skeletal maturation - Failure to thrive - Frontal bossing - Hypertelorism - Hypotelorism - Inguinal hernia - Intellectual disability - Intrauterine growth retardation - Large fontanelles - Low-set ears - Myopia - Narrow mouth - Narrow nasal ridge - Prominent forehead - Prominent superficial blood vessels - Seizures - Severe short stature - Sparse hair - Sporadic - Strabismus - Talipes equinovarus - Thin skin - Wide cranial sutures - Wormian bones - The Human Phenotype Ontology (HPO) has collected information on how often a sign or symptom occurs in a condition. Much of this information comes from Orphanet, a European rare disease database. The frequency of a sign or symptom is usually listed as a rough estimate of the percentage of patients who have that feature. The frequency may also be listed as a fraction. The first number of the fraction is how many people had the symptom, and the second number is the total number of people who were examined in one study. For example, a frequency of 25/25 means that in a study of 25 people all patients were found to have that symptom. Because these frequencies are based on a specific study, the fractions may be different if another group of patients are examined. Sometimes, no information on frequency is available. In these cases, the sign or symptom may be rare or common.\n",
       "\n",
       "**Retrieved (top-3 snippets):**  \n",
       "what are the signs and symptoms of de barsy syndrome the human phenotype ontology provides the following list of signs and symptoms for de b… | de barsy syndrome is a rare genetic disorder characterized mainly by a prematurely aged looking face progeria cloudy corneas short stature a… | what are the signs and symptoms of koolen de vries syndrome the human phenotype ontology provides the following list of signs and symptoms f…"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Shown 8 examples. Mean ROUGE-L: 0.142\n"
     ]
    }
   ],
   "source": [
    "# ===== G4 — Demo N examples with side-by-side view and ROUGE-L =====\n",
    "from IPython.display import display, Markdown\n",
    "import pandas as pd\n",
    "\n",
    "q_list = test_df[\"question\"].astype(str).tolist()\n",
    "a_list = test_df[\"answer\"].astype(str).tolist()\n",
    "\n",
    "# pick indices for the demo\n",
    "indices = list(range(len(q_list)))\n",
    "if N_SAMPLES is not None:\n",
    "    random.shuffle(indices)\n",
    "    indices = indices[:N_SAMPLES]\n",
    "\n",
    "rows = []\n",
    "for i in indices:\n",
    "    q = q_list[i]; gold = a_list[i]\n",
    "    pred, idxs, ctx, pr = generate_answer(q, topk=GEN_TOPK, style=GEN_STYLE)\n",
    "    rL = rougeL_f1(pred, gold)\n",
    "    snippet_join = \" | \".join([str(ACTIVE_PASSAGES[j]).replace(\"\\n\",\" \")[:140] + \"…\" for j in idxs])\n",
    "\n",
    "    rows.append({\n",
    "        \"idx\": i,\n",
    "        \"rougeL\": round(rL, 3),\n",
    "        \"question\": q,\n",
    "        \"generated\": pred,\n",
    "        \"gold\": gold,\n",
    "        \"retrieved_snippets\": snippet_join\n",
    "    })\n",
    "\n",
    "df_demo = pd.DataFrame(rows).sort_values(\"rougeL\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "def _md_block(row):\n",
    "    return (\n",
    "f\"**Q (#{row['idx']}):** {row['question']}\\n\\n\"\n",
    "f\"**Generated (ROUGE-L={row['rougeL']:.3f}):**  \\n{row['generated']}\\n\\n\"\n",
    "f\"**Gold:**  \\n{row['gold']}\\n\\n\"\n",
    "f\"**Retrieved (top-{GEN_TOPK} snippets):**  \\n{row['retrieved_snippets']}\"\n",
    "    )\n",
    "\n",
    "for _, r in df_demo.iterrows():\n",
    "    display(Markdown(_md_block(r)))\n",
    "\n",
    "print(f\"\\n✅ Shown {len(df_demo)} examples. Mean ROUGE-L: {df_demo['rougeL'].mean():.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (medquad_env)",
   "language": "python",
   "name": "medquad_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
